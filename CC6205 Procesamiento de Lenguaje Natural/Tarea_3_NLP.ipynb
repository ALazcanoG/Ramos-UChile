{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "GH5VYTyEFyek",
        "EoR4e09KGEDV",
        "yYpgOYJYGGo4",
        "PBajYCYdGIGD"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ckbt7VPDhBwb"
      },
      "source": [
        "# **Tarea 3 - Word Embeddings üìö**\n",
        "\n",
        "**Integrantes:** Arturo Lazcano\n",
        "\n",
        "**Fecha l√≠mite de entrega üìÜ:** 16 de mayo.\n",
        "\n",
        "**Tiempo estimado de dedicaci√≥n:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-19T18:30:18.109327Z",
          "start_time": "2020-03-19T18:30:18.103344Z"
        },
        "id": "q5CSRY4oNCHK"
      },
      "source": [
        "\n",
        "**Instrucciones:**\n",
        "- El ejercicio consiste en:\n",
        "    - Responder preguntas relativas a los contenidos vistos en los v√≠deos y slides de las clases.\n",
        "    - Implementar el m√©todo de la Word Context Matrix. \n",
        "    - Entrenar Word2Vec y FastText sobre un peque√±o corpus.\n",
        "    - Evaluar los embeddings obtenidos en una tarea de clasificaci√≥n.\n",
        "- La tarea se realiza en grupos de **m√°ximo** 2 personas. Puede ser invidivual pero no es recomendable.\n",
        "- La entrega es a trav√©s de u-cursos a m√°s tardar el d√≠a estipulado arriba. No se aceptan atrasos.\n",
        "- El formato de entrega es este mismo **Jupyter Notebook**.\n",
        "- Al momento de la revisi√≥n tu c√≥digo ser√° ejecutado. Por favor verifica que tu entrega no tenga errores de compilaci√≥n. \n",
        "\n",
        "\n",
        "**Referencias**\n",
        "\n",
        "V√≠deos: \n",
        "\n",
        "- [Linear Models](https://youtu.be/zhBxDsNLZEA)\n",
        "- [Neural Networks](https://youtu.be/oHZHA8h2xN0)\n",
        "- [Word Embeddings](https://youtu.be/wtwUsJMC9CA)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4wYf0vgnbTv"
      },
      "source": [
        "## **Preguntas te√≥ricas üìï (3 puntos).** ##\n",
        "Para estas preguntas no es necesario implementar c√≥digo, pero pueden utilizar pseudo c√≥digo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5hUG6-8ngoK"
      },
      "source": [
        "### **Parte 1: Modelos Lineales (1.5 ptos)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yRvZbhsoi8f"
      },
      "source": [
        "Suponga que tiene un dataset de 10.000 documentos etiquetados por 4 categor√≠as: pol√≠tica, deporte, negocios y otros. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irsqBVmCnx3M"
      },
      "source": [
        "**Pregunta 1**: Dise√±e un modelo lineal capaz de clasificar un documento seg√∫n estas categor√≠as donde el output sea un vector con una distribuci√≥n de probabilidad con la pertenencia a cada clase. \n",
        "\n",
        "Especifique: representaci√≥n de los documentos de entrada, par√°metros del modelo, transformaciones necesarias para obtener la probabilidad de cada etiqueta y funci√≥n de p√©rdida escogida. **(0.75 puntos)**\n",
        "\n",
        "**Respuesta**:  \n",
        "\n",
        "Se puede usar bow con tal de obtener vectores que representen frecuencias de palabras. Luego, los par√°metros del modelo son escritos como $\\theta$ donde estos representan los pesos en una regresi√≥n log√≠stica multiclase (modelo lineal) donde podemos usar la versi√≥n de softmax para obtener un output de distribuci√≥n de probabilidad. Por √∫ltimo, para la funci√≥n de p√©rdida, se puede escoger categorical-cross-entropy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5FaWqBVvL90"
      },
      "source": [
        "**Pregunta 2**: Explique c√≥mo funciona el proceso de entrenamiento en este tipo de modelos y su evaluaci√≥n. **(0.75 puntos)**\n",
        "\n",
        "**Respuesta**:  \n",
        "\n",
        "El objetivo del entrenamiento es encontrar los buenos par√°metros, es decir, $\\theta$, lo cual significan los pesos en la regresi√≥n log√≠stica nombrada en la pregunta anterior. Para esto, se escogen pesos al azar, se calcula el output del modelo junto con la funci√≥n de p√©rdida (cross entropy en este caso) y su gradiente para luego actualizar los pesos utilizando el c√°lculo del gradiente (o alg√∫n otro algoritmo como SGD) e iterar varias veces este proceso para llegar a un \"√≥ptimo\" (puede no ser un √≥ptimo matem√°ticamente pero es una aproximaci√≥n).  \n",
        "Para evaluarlo, se requieren m√©tricas (accuracy, f1 score, recall, entre otras) de acuerdo al objetivo del problema, y estas deben ser calculadas con un conjunto de datos aparte del conjunto con el que se ha entrenado el modelo "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkK7pc54njZq"
      },
      "source": [
        "### **Parte 2: Redes Neuronales (1.5 ptos)** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUbJjlj_9AFC"
      },
      "source": [
        "Supongamos que tenemos la siguiente red neuronal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obUfuOYB_TOC"
      },
      "source": [
        "![image.png](https://drive.google.com/uc?export=view&id=1nV1G0dOeVGPn40qGcGF9l_pVEFNtLU-w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2z-8zKW0_6q"
      },
      "source": [
        "**Pregunta 1**: En clases les explicaron como se puede representar una red neuronal de una y dos capas de manera matem√°tica. Dada la red neuronal anterior, defina la salida $\\vec{\\hat{y}}$ en funci√≥n del vector $\\vec{x}$, pesos $W^i$, bias $b^i$ y funciones $g,f,h$. \n",
        "\n",
        "Adicionalmente liste y explicite las dimensiones de cada matriz y vector involucrado en la red neuronal. **(0.75 Puntos)**\n",
        "\n",
        "**Respuesta**: \n",
        "\n",
        "Formula:\n",
        "$\\vec{\\hat{y}} = NN_{MLP3}(\\vec{x}) = h(f(g(\\vec{x}W^1 + \\vec{b}^1)W^2 + \\vec{b}^2)W^3 + \\vec{b}^3)W^4$  \n",
        "(An√°logo a la slide 8 del github del curso 'Neural Networks as Mathematical Functions')\n",
        "\n",
        "Dimensiones:  \n",
        "$ x \\in \\mathbb{R}^3 \\ ; \\ W^1 \\in \\mathbb{R}^{3 \\times 2} \\ ; \\  \\vec{b}^1, \\vec{h}^1 \\in \\mathbb{R}^2 $  \n",
        "$ W^2 \\in \\mathbb{R}^{2 \\times 3} \\ ; \\  \\vec{b}^2, \\vec{h}^2 \\in \\mathbb{R}^3 $  \n",
        "$ W^3 \\in \\mathbb{R}^{3 \\times 1} \\ ; \\  \\vec{b}^3, \\vec{h}^3 \\in \\mathbb{R}^1 $  \n",
        "$ W^4 \\in \\mathbb{R}^{1 \\times 4} \\ ; \\  \\vec{\\hat{y}} \\in \\mathbb{R}^4 $\n",
        "\n",
        "\n",
        "**Pregunta 2**: Explique qu√© es backpropagation. ¬øCuales ser√≠an los par√°metros a evaluar en la red neuronal anterior durante backpropagation? **(0.25 puntos)**\n",
        "\n",
        "**Respuesta**:  \n",
        "\n",
        "Es un algoritmo en el entrenamiento de modelos de redes neuronales, que se utiliza para calcular el gradiente de la funci√≥n de p√©rdida ($L$, a escoger) de un modelo en funci√≥n de sus par√°metros, y as√≠ actualizar los par√°metros para mejorar la calidad de las predicciones del modelo.  \n",
        "Los par√°metros a evaluar en la red anterior durante este proceso son:  \n",
        "$Œ¥^l_{[j]} ‚â° \\frac{\\partial L}{‚àÇ\\vec{h}^l_{[j]}}, \\quad \\frac{‚àÇ\\vec{h}^l_{[j]}}{\\partial W^l_{[i, j]}} = \\vec{z}^{(l-1)}_{[i]}, \\quad \\frac{\\partial L}{\\partial W^l_{[i, j]}} =  Œ¥^l_{[j]} √ó \\vec{z}^{(l-1)}_{[i]} $\n",
        "\n",
        "**Pregunta 3**: Explique los pasos de backpropagation. En la red neuronal anterior: Cuales son las derivadas que debemos calcular para poder obtener $\\vec{\\delta^l_{[j]}}$ en todas las capas? **(0.5 puntos)**\n",
        "\n",
        "**Respuesta**:  \n",
        "\n",
        "Propaga los errores de predicci√≥n hacia atr√°s a trav√©s del modelo desde la salida hasta la entrada, para determinar cu√°nto cada par√°metro del modelo contribuye a esos errores. Esta propagaci√≥n hacia atr√°s se realiza mediante la aplicaci√≥n de la regla de la cadena para calcular las derivadas parciales de $L$ con respecto a cada par√°metro del modelo $\\theta$. Luego, se actualizan los par√°metros utilizando este gradiente y un algoritmo de optimizaci√≥n.  \n",
        "Este proceso se repite varias veces hasta encontrar una aproximaci√≥n de los par√°metros √≥ptimos.  \n",
        "\n",
        "La derivadas que se deben calcular para obtener $\\vec{\\delta^l_{[j]}}$ en todas las capas son:  \n",
        "\n",
        "$ \\frac{\\partial L}{\\partial \\vec{h}^1_{[1,1]}}, \\quad \\frac{\\partial L}{\\partial \\vec{h}^1_{[1,2]}}, \\quad \\frac{\\partial L}{\\partial \\vec{h}^2_{[1,1]}}, \\quad \\frac{\\partial L}{\\partial \\vec{h}^2_{[1,2]}}, \\quad \\frac{\\partial L}{\\partial \\vec{h}^2_{[1,3]}}, \\quad \\frac{\\partial L}{\\partial \\vec{h}^3_{[1,1]}} $"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocS_vQhR1gcU"
      },
      "source": [
        "## **Preguntas pr√°cticas üíª (3 puntos).** ##"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parte 3 A (1 Punto): Word Contex Matrix"
      ],
      "metadata": {
        "id": "D0wk5GBkSE73"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "En esta parte debe crear una matriz palabra contexto, para esto, complete el siguiente template (para esta parte puede utilizar las librer√≠as ```numpy``` y/o ```scipy```). Hint: revise como utilizar matrices sparse de ```scipy```\n",
        "\n",
        "```python\n",
        "class WordContextMatrix:\n",
        "\n",
        "  def __init__(self, vocab_size, window_size, dataset, tokenizer):\n",
        "    \"\"\"\n",
        "    Utilice el constructor para definir los parametros.\n",
        "    \"\"\"\n",
        "\n",
        "    # se sugiere agregar un una estructura de datos para guardar las\n",
        "    # palabras del vocab y para guardar el conteo de coocurrencia\n",
        "    # si lo necesita puede agregar m√°s parametros pero no puede cambiar el resto\n",
        "    ...\n",
        "    \n",
        "  def build_vocab(self, word):\n",
        "    \"\"\"\n",
        "    Utilice este m√©todo para construir el vocabulario\n",
        "    \"\"\"\n",
        "    \n",
        "\n",
        "    # Le puede ser √∫til considerar un token unk al vocab\n",
        "    # para palabras fuera del vocab\n",
        "    ...\n",
        "  \n",
        "  def build_matrix(self):\n",
        "    \"\"\"\n",
        "    Utilice este m√©todo para crear la palabra contexto\n",
        "    \"\"\"\n",
        "    ...\n",
        "\n",
        "  def get_matrix(self):\n",
        "    \"\"\"\n",
        "    Utilice este m√©todo para obtener la matriz palabra contexto. \n",
        "    \"\"\"\n",
        "\n",
        "    # se recomienda transformar la matrix a un diccionario de embedding.\n",
        "    # por ejemplo {palabra1:vec1, palabra2:vec2, ...}\n",
        "    ...\n",
        "\n",
        "```\n",
        "\n",
        "puede modificar los par√°metros o m√©todos si lo considera necesario. Para probar la matrix puede utilizar el siguiente corpus.\n",
        "\n",
        "```python\n",
        "corpus = [\n",
        "  \"I like deep learning.\",\n",
        "  \"I like NLP.\",\n",
        "  \"I enjoy flying.\"\n",
        "]\n",
        "```\n",
        "\n",
        "Obteniendo una matriz parecia a esta:\n",
        "\n",
        "***Resultado esperado***: \n",
        "\n",
        "| counts   | I  | like | enjoy | deep | learning | NLP | flying | . |   \n",
        "|----------|---:|-----:|------:|-----:|---------:|----:|-------:|--:|\n",
        "| I        | 0  |  2   |  1    |    0 |  0       |   0 | 0      | 0|            \n",
        "| like     |  2 |    0 |  0    |    1 |  0       |   1 | 0      | 0 | \n",
        "| enjoy    |  1 |    0 |  0    |    0 |  0       |   0 | 1      | 0 |\n",
        "| deep     |  0 |    1 |  0    |    0 |  1       |   0 | 0      | 0 |  \n",
        "| learning |  0 |    0 |  0    |    1 |  0       |   0 | 0      | 1 |          \n",
        "| NLP      |  0 |    1 |  0    |    0 |  0       |   0 | 0      | 1 |\n",
        "| flying   |  0 |    0 |  1    |    0 |  0       |   0 | 0      | 1 | \n",
        "| .        |  0 |    0 |  0    |    0 |  1       |   1 | 1      | 0 | \n",
        "\n",
        "``\n",
        "\n",
        "Verifique si su matrix es igual a esta utilizando el corpus de ejemplo. Ojo que este es s√≥lo un ejemplo, su algoritmo debe **generalizar** a otros ejemplos."
      ],
      "metadata": {
        "id": "e_mh12Z9SF-J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Se mueve la celda de imports para que no entregue problemas la creaci√≥n de la clase)"
      ],
      "metadata": {
        "id": "MJj3nGsI_D07"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecCvnryeQiG7"
      },
      "source": [
        "import re  \n",
        "import pandas as pd \n",
        "from time import time  \n",
        "from collections import defaultdict \n",
        "import string \n",
        "import multiprocessing\n",
        "import os\n",
        "import gensim\n",
        "import sklearn\n",
        "from sklearn import linear_model\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, cohen_kappa_score, classification_report\n",
        "\n",
        "# word2vec\n",
        "from gensim.models import Word2Vec, KeyedVectors, FastText\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "from sklearn.model_selection import train_test_split\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WordContextMatrix:\n",
        "\n",
        "  def __init__(self, vocab_size, window_size, dataset, tokenizer):\n",
        "    \"\"\"\n",
        "    Utilice el constructor para definir los parametros.\n",
        "    \"\"\"\n",
        "\n",
        "    # se sugiere agregar un una estructura de datos para guardar las\n",
        "    # palabras del vocab y para guardar el conteo de coocurrencia\n",
        "    # si lo necesita puede agregar m√°s parametros pero no puede cambiar el resto\n",
        "    self.vocab_size = vocab_size\n",
        "    self.window_size = window_size\n",
        "    self.dataset = dataset\n",
        "    self.tokenizer = tokenizer\n",
        "    self.vocab = set() #[]\n",
        "    self.d = defaultdict(int)\n",
        "    self.df = None\n",
        "\n",
        "  def build_vocab(self):\n",
        "    \"\"\"\n",
        "    Utilice este m√©todo para construir el vocabulario\n",
        "    \"\"\"\n",
        "\n",
        "    # Le puede ser √∫til considerar un token unk al vocab\n",
        "    # para palabras fuera del vocab\n",
        "    #palabras = []\n",
        "    #for d in self.dataset:\n",
        "    #  palabras = palabras + self.tokenizer(d)\n",
        "    #L = []\n",
        "    #L.extend(Counter(palabras).most_common(self.vocab_size))\n",
        "    ##n = len(self.vocab)\n",
        "    #for p,i in L:\n",
        "    #  n = len(self.vocab)\n",
        "    #  if (p not in self.vocab) & (n<=self.vocab_size):\n",
        "    #    self.vocab.append(p)\n",
        "    for d in self.dataset:\n",
        "      for token in self.tokenizer(d):\n",
        "        self.vocab.add(token)\n",
        "\n",
        "\n",
        "\n",
        "  def build_matrix(self):\n",
        "    \"\"\"\n",
        "    Utilice este m√©todo para crear la palabra contexto\n",
        "    \"\"\"\n",
        "    for text in self.dataset:\n",
        "      token_text = self.tokenizer(text)\n",
        "      for i in range(len(token_text)):\n",
        "        token = token_text[i]\n",
        "        next_token = token_text[i+1 : i+1+self.window_size]\n",
        "        for t in next_token:\n",
        "          key = tuple(sorted([t, token]))\n",
        "          self.d[key] += 1\n",
        "\n",
        "  def get_matrix(self):\n",
        "    \"\"\"\n",
        "    Utilice este m√©todo para obtener la matriz palabra contexto. \n",
        "    \"\"\"\n",
        "\n",
        "    # se recomienda transformar la matrix a un diccionario de embedding.\n",
        "    # por ejemplo {palabra1:vec1, palabra2:vec2, ...}\n",
        "\n",
        "    #self.vocab = sorted(self.vocab)\n",
        "    self.vocab = list(self.vocab)\n",
        "    n = len(self.vocab)\n",
        "    M = np.zeros((n, n), dtype=np.int16)\n",
        "    self.df = pd.DataFrame(data= M, index=self.vocab, columns=self.vocab)\n",
        "    i = 0\n",
        "    print(len(self.d.items()))\n",
        "    for key, value in self.d.items():\n",
        "      if (key[0] in self.vocab) and (key[1] in self.vocab):\n",
        "        self.df[key[0]][key[1]] = self.df[key[1]][key[0]] = value\n",
        "    return self.df\n",
        "\n",
        "  def get_dict(self):\n",
        "    \"\"\"\n",
        "    M√©todo para obtener el diccionario asociado\n",
        "    \"\"\"\n",
        "    # {palabra1:vec1, palabra2:vec2, ...}\n",
        "    dic_embedding = {}\n",
        "    n = len(self.vocab)\n",
        "    for p in self.vocab:\n",
        "      dic_embedding[p] = self.df[p].values\n",
        "    return dic_embedding"
      ],
      "metadata": {
        "id": "cbbE_DwI-u8z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "  \"I like deep learning.\",\n",
        "  \"I like NLP.\",\n",
        "  \"I enjoy flying.\"\n",
        "]"
      ],
      "metadata": {
        "id": "BVOXtaknDQY5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizer auxiliar 2:\n",
        "\n",
        "# limpiar puntuaciones y separar por tokens.\n",
        "punctuation = string.punctuation + \"¬´¬ª‚Äú‚Äù‚Äò‚Äô‚Ä¶‚Äî\"\n",
        "stopwords = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/Alir3z4/stop-words/master/spanish.txt'\n",
        ").values\n",
        "stopwords = Counter(stopwords.flatten().tolist())\n",
        "\n",
        "def simple_tokenizer(doc, lower=False):\n",
        "    if lower:\n",
        "        tokenized_doc = doc.translate(str.maketrans(\n",
        "            '', '', punctuation)).lower().split()\n",
        "\n",
        "    tokenized_doc = doc.translate(str.maketrans('', '', punctuation)).split()\n",
        "    tokenized_doc = [\n",
        "        token for token in tokenized_doc if token.lower() not in stopwords\n",
        "    ]\n",
        "    return tokenized_doc"
      ],
      "metadata": {
        "id": "RK6qMXjMN4D7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "M = WordContextMatrix(21, window_size=1, dataset=corpus, tokenizer=simple_tokenizer)\n",
        "M.build_vocab()"
      ],
      "metadata": {
        "id": "E8OygYy3DRgI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "M.build_matrix()"
      ],
      "metadata": {
        "id": "gnC5hJvcUUkc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "M.d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TV5xi7WitNGX",
        "outputId": "55c508f3-fee4-427e-bb6c-2f701630ef77"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int,\n",
              "            {('I', 'like'): 2,\n",
              "             ('deep', 'like'): 1,\n",
              "             ('deep', 'learning'): 1,\n",
              "             ('NLP', 'like'): 1,\n",
              "             ('I', 'enjoy'): 1,\n",
              "             ('enjoy', 'flying'): 1})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "M.get_matrix()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "f1kdJt4pRWqm",
        "outputId": "7879cd64-869b-44b3-e46e-fe04507ff82e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          like  learning  I  flying  enjoy  NLP  deep\n",
              "like         0         0  2       0      0    1     1\n",
              "learning     0         0  0       0      0    0     1\n",
              "I            2         0  0       0      1    0     0\n",
              "flying       0         0  0       0      1    0     0\n",
              "enjoy        0         0  1       1      0    0     0\n",
              "NLP          1         0  0       0      0    0     0\n",
              "deep         1         1  0       0      0    0     0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d01901e1-6534-44fb-8b58-8dc5d874d70e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>like</th>\n",
              "      <th>learning</th>\n",
              "      <th>I</th>\n",
              "      <th>flying</th>\n",
              "      <th>enjoy</th>\n",
              "      <th>NLP</th>\n",
              "      <th>deep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>like</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>learning</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>flying</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>enjoy</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NLP</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>deep</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d01901e1-6534-44fb-8b58-8dc5d874d70e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d01901e1-6534-44fb-8b58-8dc5d874d70e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d01901e1-6534-44fb-8b58-8dc5d874d70e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "M.get_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JIaQRO1Izt_",
        "outputId": "7856d17d-86b2-4848-e7ff-81c50db5f708"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'like': array([0, 0, 2, 0, 0, 1, 1], dtype=int16),\n",
              " 'learning': array([0, 0, 0, 0, 0, 0, 1], dtype=int16),\n",
              " 'I': array([2, 0, 0, 0, 1, 0, 0], dtype=int16),\n",
              " 'flying': array([0, 0, 0, 0, 1, 0, 0], dtype=int16),\n",
              " 'enjoy': array([0, 0, 1, 1, 0, 0, 0], dtype=int16),\n",
              " 'NLP': array([1, 0, 0, 0, 0, 0, 0], dtype=int16),\n",
              " 'deep': array([1, 1, 0, 0, 0, 0, 0], dtype=int16)}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ac√° el uso del tokenizer del auxiliar 2 no cuenta los puntos `.` pero se puede usar otro para igualar la respuesta que entrega esta clase con la esperada."
      ],
      "metadata": {
        "id": "T_JsPxih97ui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4I8QJPty-lCT",
        "outputId": "8b53fd59-9ce9-4df4-d72b-f52ff540d94a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "M2 = WordContextMatrix(21, window_size=1, dataset=corpus, tokenizer=word_tokenize)\n",
        "M2.build_vocab()"
      ],
      "metadata": {
        "id": "_rz3GbXd-QsR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "M2.build_matrix()"
      ],
      "metadata": {
        "id": "QVSGQtr6-XzP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "M2.get_matrix()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "AuLWiXPQ-ZYb",
        "outputId": "068c7aca-4c8e-472d-9529-2c2965ed97a8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          like  learning  I  flying  enjoy  deep  NLP  .\n",
              "like         0         0  2       0      0     1    1  0\n",
              "learning     0         0  0       0      0     1    0  1\n",
              "I            2         0  0       0      1     0    0  0\n",
              "flying       0         0  0       0      1     0    0  1\n",
              "enjoy        0         0  1       1      0     0    0  0\n",
              "deep         1         1  0       0      0     0    0  0\n",
              "NLP          1         0  0       0      0     0    0  1\n",
              ".            0         1  0       1      0     0    1  0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce96738f-5cc5-4fe5-ba25-fffc70d23bf0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>like</th>\n",
              "      <th>learning</th>\n",
              "      <th>I</th>\n",
              "      <th>flying</th>\n",
              "      <th>enjoy</th>\n",
              "      <th>deep</th>\n",
              "      <th>NLP</th>\n",
              "      <th>.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>like</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>learning</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>flying</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>enjoy</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>deep</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NLP</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>.</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce96738f-5cc5-4fe5-ba25-fffc70d23bf0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ce96738f-5cc5-4fe5-ba25-fffc70d23bf0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ce96738f-5cc5-4fe5-ba25-fffc70d23bf0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol82nJ0FnmcP"
      },
      "source": [
        "### **Parte 3 B (1 Punto): Word Embeddings**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgmeSFqKLpFL"
      },
      "source": [
        "En la auxiliar 2 aprendieron como entrenar Word2Vec utilizando gensim. El objetivo de esta parte es comparar los embeddings obtenidos con dos modelos diferentes: Word2Vec y [FastText](https://radimrehurek.com/gensim/models/fasttext.html) (utilizen size=200 en FastText) entrenados en el mismo dataset de di√°logos de los Simpson. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZgN06q4QPi3"
      },
      "source": [
        "Utilizando el dataset adjunto con la tarea:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY3kmg4onnsu"
      },
      "source": [
        "data_file = \"dialogue-lines-of-the-simpsons.zip\"\n",
        "df = pd.read_csv(data_file)\n",
        "stopwords = pd.read_csv(\n",
        "    'https://raw.githubusercontent.com/Alir3z4/stop-words/master/english.txt'\n",
        ").values\n",
        "stopwords = Counter(stopwords.flatten().tolist())\n",
        "df = df.dropna().reset_index(drop=True) # Quitar filas vacias"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAg5a5bmWk3T"
      },
      "source": [
        "**Pregunta 1**: Ayud√°ndose de los pasos vistos en la auxiliar, entrene los modelos Word2Vec y FastText sobre el dataset anterior. **(1 punto)** (Hint, le puede servir explorar un poco los datos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWw2fXFRXe5Y"
      },
      "source": [
        "**Respuesta**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvwplz7yTNcr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "738f63c4-a8f5-4757-b0e8-d684e16834c1"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        raw_character_text                                       spoken_words\n",
              "0              Miss Hoover  No, actually, it was a little of both. Sometim...\n",
              "1             Lisa Simpson                             Where's Mr. Bergstrom?\n",
              "2              Miss Hoover  I don't know. Although I'd sure like to talk t...\n",
              "3             Lisa Simpson                         That life is worth living.\n",
              "4  Edna Krabappel-Flanders  The polls will be open from now until the end ...\n",
              "5            Martin Prince        I don't think there's anything left to say.\n",
              "6  Edna Krabappel-Flanders                                              Bart?\n",
              "7             Bart Simpson                     Victory party under the slide!\n",
              "8             Lisa Simpson                      Mr. Bergstrom! Mr. Bergstrom!\n",
              "9                 Landlady  Hey, hey, he Moved out this morning. He must h..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-038ada6d-c28b-42c8-bd0e-af28fc5f31c6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>raw_character_text</th>\n",
              "      <th>spoken_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Miss Hoover</td>\n",
              "      <td>No, actually, it was a little of both. Sometim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Lisa Simpson</td>\n",
              "      <td>Where's Mr. Bergstrom?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Miss Hoover</td>\n",
              "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lisa Simpson</td>\n",
              "      <td>That life is worth living.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Edna Krabappel-Flanders</td>\n",
              "      <td>The polls will be open from now until the end ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Martin Prince</td>\n",
              "      <td>I don't think there's anything left to say.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Edna Krabappel-Flanders</td>\n",
              "      <td>Bart?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Bart Simpson</td>\n",
              "      <td>Victory party under the slide!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Lisa Simpson</td>\n",
              "      <td>Mr. Bergstrom! Mr. Bergstrom!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Landlady</td>\n",
              "      <td>Hey, hey, he Moved out this morning. He must h...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-038ada6d-c28b-42c8-bd0e-af28fc5f31c6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-038ada6d-c28b-42c8-bd0e-af28fc5f31c6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-038ada6d-c28b-42c8-bd0e-af28fc5f31c6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "content = df['spoken_words']\n",
        "cleaned_content = [simple_tokenizer(doc) for doc in content.values]\n",
        "phrases = Phrases(cleaned_content, min_count=100, progress_per=5000) \n",
        "bigram = Phraser(phrases)\n",
        "sentences = bigram[cleaned_content]"
      ],
      "metadata": {
        "id": "8lU8Uk_BBfc6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thesimpsons = Word2Vec(min_count=10,\n",
        "                      window=4,\n",
        "                      vector_size=200,\n",
        "                      sample=6e-5,\n",
        "                      alpha=0.03,\n",
        "                      min_alpha=0.0007,\n",
        "                      negative=20,\n",
        "                      workers=multiprocessing.cpu_count())"
      ],
      "metadata": {
        "id": "3G3FmAbPAWZs"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6RvJGpbTNcs"
      },
      "source": [
        "thesimpsons.build_vocab(sentences, progress_per=10000)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = time()\n",
        "thesimpsons.train(sentences, total_examples=thesimpsons.corpus_count, epochs=5, report_delay=10)\n",
        "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DwFC8ahCPCC",
        "outputId": "904b596a-5f26-47a0-d0b7-61ffb6d9b844"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time to train the model: 0.17 mins\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "thesimpsons.init_sims(replace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f21mMLNKCnAO",
        "outputId": "415535b7-03cb-4759-a499-bbdf8280d762"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-fb84872a32c5>:1: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
            "  thesimpsons.init_sims(replace=True)\n",
            "WARNING:gensim.models.keyedvectors:destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelFT = FastText(vector_size=200, window=4, min_count=10) \n",
        "modelFT.build_vocab(corpus_iterable=sentences)\n",
        "modelFT.train(corpus_iterable=sentences, total_examples=thesimpsons.corpus_count, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQBABizFEuRB",
        "outputId": "a37d3825-1bc2-4310-af36-ff4930c6d5ce"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1604092, 2211380)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Lr8U5wOTNcr"
      },
      "source": [
        "**Pregunta 2**: Encuentre las palabras mas similares a las siguientes: Lisa, Bart, Homer, Marge. C√∫al es la diferencia entre ambos resultados? Por qu√© ocurre esto? Intente comparar ahora Liisa en ambos modelos (doble i). Cuando escoger√≠a uno vs el otro? **(0.5 puntos)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMLyGffVTNcs"
      },
      "source": [
        "**Respuesta**:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lisa"
      ],
      "metadata": {
        "id": "GH5VYTyEFyek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thesimpsons.wv.most_similar(positive=[\"Lisa\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMYn9R4lCEli",
        "outputId": "253336db-c6e5-4619-f12d-3bda9608b93b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('dedicated', 0.9996489882469177),\n",
              " ('rare', 0.9996449947357178),\n",
              " ('Catholic', 0.9996441602706909),\n",
              " ('path', 0.9996439814567566),\n",
              " ('London', 0.9996429085731506),\n",
              " ('cent', 0.9996426105499268),\n",
              " ('supply', 0.9996426105499268),\n",
              " ('ambulance', 0.9996420741081238),\n",
              " ('Lil', 0.9996417760848999),\n",
              " ('yogurt', 0.9996405243873596)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelFT.wv.most_similar(positive=[\"Lisa\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4OnxMytF5su",
        "outputId": "7684d376-9c85-41ef-c1c4-2895e753de40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Bart', 0.9991167187690735),\n",
              " ('Sim', 0.9964190721511841),\n",
              " ('Simpsons', 0.9955947399139404),\n",
              " ('Thompson', 0.9931660890579224),\n",
              " ('Simpson', 0.9896511435508728),\n",
              " ('Homer_Simpson', 0.9885438680648804),\n",
              " ('son', 0.987421452999115),\n",
              " ('Lisas', 0.9871761798858643),\n",
              " ('Barts', 0.9842827916145325),\n",
              " ('Simon', 0.9836682081222534)]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bart"
      ],
      "metadata": {
        "id": "EoR4e09KGEDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thesimpsons.wv.most_similar(positive=[\"Bart\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSjXIghAGLOp",
        "outputId": "0182346d-f5cf-4e2f-ca53-653ed65c895d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Corporation', 0.9996622800827026),\n",
              " ('Jay', 0.999652624130249),\n",
              " ('warned', 0.9996504783630371),\n",
              " ('apartment', 0.9996500611305237),\n",
              " ('Park', 0.9996492862701416),\n",
              " ('talked', 0.9996489882469177),\n",
              " ('voters', 0.9996474981307983),\n",
              " ('commercial', 0.999646782875061),\n",
              " ('combination', 0.9996466040611267),\n",
              " ('behave', 0.9996466040611267)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelFT.wv.most_similar(positive=[\"Bart\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnExxxbfGMYi",
        "outputId": "b309c585-e803-48c2-9a1a-3c62eb501419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Lisa', 0.9991167187690735),\n",
              " ('Sim', 0.9971251487731934),\n",
              " ('Simpsons', 0.996829092502594),\n",
              " ('Thompson', 0.9950379729270935),\n",
              " ('son', 0.9912339448928833),\n",
              " ('Simpson', 0.9908024072647095),\n",
              " ('Homer_Simpson', 0.9896501898765564),\n",
              " ('Lisas', 0.9872360825538635),\n",
              " ('Simon', 0.9860203862190247),\n",
              " ('Barts', 0.9859793782234192)]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Homer"
      ],
      "metadata": {
        "id": "yYpgOYJYGGo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thesimpsons.wv.most_similar(positive=[\"Homer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6nn2ZvJGNWf",
        "outputId": "1f1d607f-6692-4fff-c548-b373d4be88b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('peoples', 0.9996839761734009),\n",
              " ('beast', 0.9996734261512756),\n",
              " ('played', 0.9996723532676697),\n",
              " ('7', 0.9996711611747742),\n",
              " ('stage', 0.9996662735939026),\n",
              " ('arm', 0.999663770198822),\n",
              " ('determine', 0.9996634125709534),\n",
              " ('entered', 0.9996623396873474),\n",
              " ('mission', 0.9996620416641235),\n",
              " ('Wow', 0.9996611475944519)]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelFT.wv.most_similar(positive=[\"Homer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6Ls8qvvGNF9",
        "outputId": "b27fe101-febc-4df0-b734-25599a45cdf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Homers', 0.9992955923080444),\n",
              " ('listen', 0.9987065196037292),\n",
              " ('Homey', 0.998621940612793),\n",
              " ('Max', 0.9985838532447815),\n",
              " ('husband', 0.9985791444778442),\n",
              " ('Mark', 0.9985367655754089),\n",
              " ('husbands', 0.9985294938087463),\n",
              " ('Marjorie', 0.9985273480415344),\n",
              " ('Marco', 0.9984890222549438),\n",
              " ('girlfriend', 0.998455286026001)]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Marge"
      ],
      "metadata": {
        "id": "PBajYCYdGIGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thesimpsons.wv.most_similar(positive=[\"Marge\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMece3fEGOni",
        "outputId": "074b873b-2d1c-4baa-fb91-c5df5f4266eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('teens', 0.9996843934059143),\n",
              " ('finally', 0.9996793270111084),\n",
              " ('income', 0.9996709227561951),\n",
              " ('special', 0.9996699690818787),\n",
              " ('Simpson', 0.9996623992919922),\n",
              " ('holiday', 0.999661922454834),\n",
              " ('zone', 0.9996590614318848),\n",
              " ('bet', 0.9996586441993713),\n",
              " ('Duncan', 0.9996581673622131),\n",
              " ('Easter', 0.9996568560600281)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelFT.wv.most_similar(positive=[\"Marge\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUMMADrbGOZW",
        "outputId": "3a6ced83-9b4a-45cb-9ef4-2295e7169e23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Bar', 0.9991205930709839),\n",
              " ('Bartholomew', 0.9990481734275818),\n",
              " ('Barn', 0.9989586472511292),\n",
              " ('Maggie', 0.9989273548126221),\n",
              " ('Barry', 0.9989220499992371),\n",
              " ('Lie', 0.998871386051178),\n",
              " ('Bartdude', 0.9986646175384521),\n",
              " ('Heart', 0.9986115097999573),\n",
              " ('Bag', 0.9985683560371399),\n",
              " ('Mozart', 0.9985507130622864)]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Liisa"
      ],
      "metadata": {
        "id": "yTno5AMqGrEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# L√≠nea de c√≥digo que arroja error pues la palabra 'Liisa' no se encuentra en el vocabulario de W2V\n",
        "# (Est√° comentada para poder ejecutar todo el c√≥digo de una vez)\n",
        "\n",
        "\n",
        "# thesimpsons.wv.most_similar(positive=[\"Liisa\"])"
      ],
      "metadata": {
        "id": "fN5FIcf1GtCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelFT.wv.most_similar(positive=[\"Liisa\"])"
      ],
      "metadata": {
        "id": "T2cAatY1Gs7m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8507859-603b-4fdb-df37-0d82c221b8f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Lisa', 0.9991952180862427),\n",
              " ('Bart', 0.9987353682518005),\n",
              " ('Sim', 0.9979321360588074),\n",
              " ('Simpsons', 0.9964408874511719),\n",
              " ('Thompson', 0.9957137107849121),\n",
              " ('Homer_Simpson', 0.9932894110679626),\n",
              " ('Lisas', 0.9924702048301697),\n",
              " ('Barts', 0.9902874231338501),\n",
              " ('son', 0.9898444414138794),\n",
              " ('Simon', 0.9895915389060974)]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hay diferencias significativas en los resultados de las palabras similares mostradas en las celdas anteriores. Esto se debe a la ra√≠z del algoritmo word2vec y FastText, ya que mientras el primero trabaja a nivel de palabra y en la representaci√≥n de palabras basada en su proximidad en el corpus, FastText lo hace a nivel de n-gramas que componen una palabra.  \n",
        "\n",
        "Notar que en el caso de la palabra `Liisa`, el primer modelo no es capaz de trabajarla pues es una palabra que no se encuentra en e vocabulario, mientras que FastText s√≠ es capaz de buscar resultados similares gracias al uso de los n-gramas.  \n",
        "\n",
        "Es por esto √∫ltimo que, para recomendar un modelo que busque pasalbras similares, es preferible el algoritmo de FastText pues acepta peque√±os errores ortogr√°ficos y posee respuestas m√°s coherentes a lo que buscamos."
      ],
      "metadata": {
        "id": "p0FdKQ1mINf0"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRCB-jqgTNcs"
      },
      "source": [
        "### **Parte 4 (1 Punto): Aplicar embeddings para clasificar**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlqzlJRSTNcs"
      },
      "source": [
        "Ahora utilizaremos los embeddings que acabamos de calcular para clasificar palabras basadas en su polaridad (positivas o negativas). \n",
        "\n",
        "Para esto ocuparemos el lexic√≥n AFINN incluido en la tarea, que incluye una lista de palabras y un 1 si su connotaci√≥n es positiva y un -1 si es negativa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMskFDmHTNcs"
      },
      "source": [
        "AFINN = 'AFINN_full.csv'\n",
        "df_afinn = pd.read_csv(AFINN, sep='\\t', header=None)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaKl8hsCTNcs"
      },
      "source": [
        "Hint: Para w2v son esperables KeyErrors debido a que no todas las palabras del corpus de los simpsons tendr√°n una representaci√≥n en AFINN. Pueden utilizar esta funci√≥n auxiliar para filtrar las filas en el dataframe que no tienen embeddings (como w2v no tiene token UNK se deben ignorar)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWSSuctiTNcs"
      },
      "source": [
        "def try_apply(model,word):\n",
        "    try:\n",
        "        aux = model[word]\n",
        "        return True\n",
        "    except KeyError:\n",
        "        #logger.error('Word {} not in dictionary'.format(word))\n",
        "        return False"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrVPeEzgTNcs"
      },
      "source": [
        "**Pregunta 1**: Transforme las palabras del corpus de AFINN a la representaci√≥n en embedding que acabamos de calcular (con ambos modelos). \n",
        "\n",
        "Su dataframe final debe ser del estilo [embedding, sentimiento], donde los embeddings corresponden a $X$ y el sentimiento asociado con el embedding a $y$ (positivo/negativo, 1/-1). \n",
        "\n",
        "Para ambos modelos, separar train y test de acuerdo a la siguiente funci√≥n. **(0.75 puntos)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDcq5czXTNct"
      },
      "source": [
        "**Respuesta**:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_afinn.head(10)"
      ],
      "metadata": {
        "id": "WhX5amTjNKsp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "cc1501d0-129c-4e19-d6bf-e56fa40e78a4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              0  1\n",
              "0          tops  1\n",
              "1         groan -1\n",
              "2      perfects  1\n",
              "3       spammer -1\n",
              "4      saluting  1\n",
              "5  transgresses -1\n",
              "6      punishes -1\n",
              "7       wasting -1\n",
              "8      virulent -1\n",
              "9   complaining -1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e847601-a79e-4474-b30a-a02b8c42018d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tops</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>groan</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>perfects</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>spammer</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>saluting</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>transgresses</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>punishes</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>wasting</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>virulent</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>complaining</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e847601-a79e-4474-b30a-a02b8c42018d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e847601-a79e-4474-b30a-a02b8c42018d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e847601-a79e-4474-b30a-a02b8c42018d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_afinn[1].value_counts()"
      ],
      "metadata": {
        "id": "au_rtW_tRPeh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e8ec505-909d-4bf6-db38-347992a73234"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1    2206\n",
              " 1    1176\n",
              "Name: 1, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(columns=['embedding', 'sentimiento'])\n",
        "embeddings = []\n",
        "sentimientos = []\n",
        "\n",
        "for i in range(len(df_afinn)):\n",
        "  if try_apply(thesimpsons.wv.key_to_index, df_afinn[0][i]):\n",
        "    embeddings.append(thesimpsons.wv[df_afinn[0][i]])\n",
        "    sentimientos.append(df_afinn[1][i])"
      ],
      "metadata": {
        "id": "eptZSwGTy6Bc"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['embedding'] = embeddings\n",
        "df['sentimiento'] = sentimientos\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "R3diZUyY5XZ4",
        "outputId": "a8fac6f8-4f13-4c15-939c-79c3316e2643"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             embedding  sentimiento\n",
              "0    [-0.0421623, 0.002720246, 0.11214883, -0.01286...            1\n",
              "1    [-0.045751717, 0.00540757, 0.112249956, -0.015...           -1\n",
              "2    [-0.04591041, 0.004843714, 0.11190602, -0.0149...           -1\n",
              "3    [-0.046466503, 0.0038215371, 0.11116661, -0.01...            1\n",
              "4    [-0.04358964, 0.00063840655, 0.109308094, -0.0...            1\n",
              "..                                                 ...          ...\n",
              "846  [-0.045184348, 0.0032837768, 0.10970671, -0.01...           -1\n",
              "847  [-0.04584969, 0.0054327804, 0.11074155, -0.012...           -1\n",
              "848  [-0.04424253, 0.0017018022, 0.108484544, -0.01...            1\n",
              "849  [-0.04634418, 0.0008307548, 0.11124904, -0.013...            1\n",
              "850  [-0.042963807, 0.003947696, 0.112631485, -0.01...            1\n",
              "\n",
              "[851 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a6fe684-1c37-4c8e-9fab-cb77432e283f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>embedding</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[-0.0421623, 0.002720246, 0.11214883, -0.01286...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-0.045751717, 0.00540757, 0.112249956, -0.015...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[-0.04591041, 0.004843714, 0.11190602, -0.0149...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[-0.046466503, 0.0038215371, 0.11116661, -0.01...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[-0.04358964, 0.00063840655, 0.109308094, -0.0...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>846</th>\n",
              "      <td>[-0.045184348, 0.0032837768, 0.10970671, -0.01...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>847</th>\n",
              "      <td>[-0.04584969, 0.0054327804, 0.11074155, -0.012...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>848</th>\n",
              "      <td>[-0.04424253, 0.0017018022, 0.108484544, -0.01...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>849</th>\n",
              "      <td>[-0.04634418, 0.0008307548, 0.11124904, -0.013...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>850</th>\n",
              "      <td>[-0.042963807, 0.003947696, 0.112631485, -0.01...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>851 rows √ó 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a6fe684-1c37-4c8e-9fab-cb77432e283f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1a6fe684-1c37-4c8e-9fab-cb77432e283f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1a6fe684-1c37-4c8e-9fab-cb77432e283f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDKe4gA3TNct"
      },
      "source": [
        "**Pregunta 2**: Entrenar una regresi√≥n log√≠stica (vista en auxiliar) y reportar accuracy, precision, recall, f1 y confusion_matrix para ambos modelos. Por qu√© se obtienen estos resultados? C√≥mo los mejorar√≠as? **(0.75 puntos)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJMzq_dETNct"
      },
      "source": [
        "**Respuesta**:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer doc2vec del auxiliar 2\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class Doc2VecTransformer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\" Transforma textos a representaciones vectoriales usando alg√∫n modelo de Word Embeddings.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, model, aggregation_func):\n",
        "        # extraemos los embeddings desde el objeto contenedor. ojo con esta parte.\n",
        "        self.model = model.wv \n",
        "        \n",
        "        # indicamos la funci√≥n de agregaci√≥n (np.min, np.max, np.mean, np.sum, ...)\n",
        "        self.aggregation_func = aggregation_func\n",
        "\n",
        "    def simple_tokenizer(self, doc, lower=False):\n",
        "        \"\"\"Tokenizador. Elimina signos de puntuaci√≥n, lleva las letras a min√∫scula(opcional) y \n",
        "           separa el tweet por espacios.\n",
        "        \"\"\"\n",
        "        if lower:\n",
        "            doc.translate(str.maketrans('', '', string.punctuation)).lower().split()\n",
        "        return doc.translate(str.maketrans('', '', string.punctuation)).split()\n",
        "    \n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        \n",
        "        doc_embeddings = []\n",
        "        \n",
        "        for doc in X:\n",
        "            # tokenizamos el documento. Se llevan todos los tokens a min√∫scula. \n",
        "            # ojo con esto, ya que puede que tokens con min√∫scula y may√∫scula tengan\n",
        "            # distintas representaciones\n",
        "            tokens = self.simple_tokenizer(doc, lower = True) \n",
        "            \n",
        "            selected_wv = []\n",
        "            for token in tokens:\n",
        "                if token in self.model.index_to_key:\n",
        "                    selected_wv.append(self.model[token])\n",
        "                    \n",
        "            # si seleccionamos por lo menos un embedding para el tweet, lo agregamos y luego lo a√±adimos.\n",
        "            if len(selected_wv) > 0:\n",
        "                doc_embedding = self.aggregation_func(np.array(selected_wv), axis=0)\n",
        "                doc_embeddings.append(doc_embedding)\n",
        "            # si no, a√±adimos un vector de ceros que represente a ese documento.\n",
        "            else: \n",
        "                # print('No pude encontrar ning√∫n embedding en el tweet: {}. Agregando vector de ceros.'.format(doc))\n",
        "                doc_embeddings.append(np.zeros(self.model.vector_size)) # la dimension del modelo \n",
        "\n",
        "        return np.array(doc_embeddings)"
      ],
      "metadata": {
        "id": "AXS3zYmvKUAA"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_afinn[0].values\n",
        "y = df_afinn[1].values\n",
        "X_2 = df['embedding'].values\n",
        "y_2 = df['sentimiento'].values"
      ],
      "metadata": {
        "id": "6FFzc1pZMw7D"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Bkt26BwTNcs"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.1, stratify=y)\n",
        "#X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, random_state=0, test_size=0.1, stratify=y_2)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upAn_eT4TNct"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000000)\n",
        "\n",
        "doc2vec_mean = Doc2VecTransformer(thesimpsons, np.mean)\n",
        "doc2vec_sum = Doc2VecTransformer(thesimpsons, np.sum)\n",
        "doc2vec_max = Doc2VecTransformer(thesimpsons, np.max)\n",
        "\n",
        "\n",
        "pipeline = Pipeline([('doc2vec', doc2vec_sum), ('clf', clf)])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "l626FlAtcTLY",
        "outputId": "f33c46a1-7138-48d6-da19-2b4cf5a5c0dc"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('doc2vec',\n",
              "                 Doc2VecTransformer(aggregation_func=<function sum at 0x7f5044132e60>,\n",
              "                                    model=<gensim.models.keyedvectors.KeyedVectors object at 0x7f4ff5904b20>)),\n",
              "                ('clf', LogisticRegression(max_iter=1000000))])"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;doc2vec&#x27;,\n",
              "                 Doc2VecTransformer(aggregation_func=&lt;function sum at 0x7f5044132e60&gt;,\n",
              "                                    model=&lt;gensim.models.keyedvectors.KeyedVectors object at 0x7f4ff5904b20&gt;)),\n",
              "                (&#x27;clf&#x27;, LogisticRegression(max_iter=1000000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;doc2vec&#x27;,\n",
              "                 Doc2VecTransformer(aggregation_func=&lt;function sum at 0x7f5044132e60&gt;,\n",
              "                                    model=&lt;gensim.models.keyedvectors.KeyedVectors object at 0x7f4ff5904b20&gt;)),\n",
              "                (&#x27;clf&#x27;, LogisticRegression(max_iter=1000000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Doc2VecTransformer</label><div class=\"sk-toggleable__content\"><pre>Doc2VecTransformer(aggregation_func=&lt;function sum at 0x7f5044132e60&gt;,\n",
              "                   model=&lt;gensim.models.keyedvectors.KeyedVectors object at 0x7f4ff5904b20&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000000)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = pipeline.predict(X_test)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(conf_matrix)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cQKRiWdcaV5",
        "outputId": "48c3d4c8-d442-42c5-922b-0ca0f91d3cd1"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[220   1]\n",
            " [116   2]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.65      1.00      0.79       221\n",
            "           1       0.67      0.02      0.03       118\n",
            "\n",
            "    accuracy                           0.65       339\n",
            "   macro avg       0.66      0.51      0.41       339\n",
            "weighted avg       0.66      0.65      0.53       339\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import FeatureUnion \n",
        "\n",
        "# Definimos el vectorizador para convertir el texto a BoW:\n",
        "vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 2))\n",
        "\n",
        "# Definimos el clasificador que usaremos.\n",
        "clf_2 = LogisticRegression(max_iter=10000)\n",
        "\n",
        "# Definimos el pipeline\n",
        "pipeline_2 = Pipeline([('features',\n",
        "                        FeatureUnion([('bow', CountVectorizer()),\n",
        "                                      ('doc2vec', doc2vec_sum)])), ('clf', clf)])"
      ],
      "metadata": {
        "id": "lJPymhfXeEMM"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_2.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "5n_OFpuneFbI",
        "outputId": "1cf05f17-046b-42f1-caee-335867c51a4d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('features',\n",
              "                 FeatureUnion(transformer_list=[('bow', CountVectorizer()),\n",
              "                                                ('doc2vec',\n",
              "                                                 Doc2VecTransformer(aggregation_func=<function sum at 0x7f5044132e60>,\n",
              "                                                                    model=<gensim.models.keyedvectors.KeyedVectors object at 0x7f4ff5904b20>))])),\n",
              "                ('clf', LogisticRegression(max_iter=1000000))])"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;features&#x27;,\n",
              "                 FeatureUnion(transformer_list=[(&#x27;bow&#x27;, CountVectorizer()),\n",
              "                                                (&#x27;doc2vec&#x27;,\n",
              "                                                 Doc2VecTransformer(aggregation_func=&lt;function sum at 0x7f5044132e60&gt;,\n",
              "                                                                    model=&lt;gensim.models.keyedvectors.KeyedVectors object at 0x7f4ff5904b20&gt;))])),\n",
              "                (&#x27;clf&#x27;, LogisticRegression(max_iter=1000000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;features&#x27;,\n",
              "                 FeatureUnion(transformer_list=[(&#x27;bow&#x27;, CountVectorizer()),\n",
              "                                                (&#x27;doc2vec&#x27;,\n",
              "                                                 Doc2VecTransformer(aggregation_func=&lt;function sum at 0x7f5044132e60&gt;,\n",
              "                                                                    model=&lt;gensim.models.keyedvectors.KeyedVectors object at 0x7f4ff5904b20&gt;))])),\n",
              "                (&#x27;clf&#x27;, LogisticRegression(max_iter=1000000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">features: FeatureUnion</label><div class=\"sk-toggleable__content\"><pre>FeatureUnion(transformer_list=[(&#x27;bow&#x27;, CountVectorizer()),\n",
              "                               (&#x27;doc2vec&#x27;,\n",
              "                                Doc2VecTransformer(aggregation_func=&lt;function sum at 0x7f5044132e60&gt;,\n",
              "                                                   model=&lt;gensim.models.keyedvectors.KeyedVectors object at 0x7f4ff5904b20&gt;))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>bow</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>doc2vec</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Doc2VecTransformer</label><div class=\"sk-toggleable__content\"><pre>Doc2VecTransformer(aggregation_func=&lt;function sum at 0x7f5044132e60&gt;,\n",
              "                   model=&lt;gensim.models.keyedvectors.KeyedVectors object at 0x7f4ff5904b20&gt;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000000)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred2 = pipeline_2.predict(X_test)\n",
        "conf_matrix2 = confusion_matrix(y_test, y_pred2)\n",
        "print(conf_matrix2)\n",
        "print(classification_report(y_test, y_pred2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vol0N-ysKl5W",
        "outputId": "1400d875-cd5f-4887-e16f-3daa908745ed"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[220   1]\n",
            " [115   3]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.66      1.00      0.79       221\n",
            "           1       0.75      0.03      0.05       118\n",
            "\n",
            "    accuracy                           0.66       339\n",
            "   macro avg       0.70      0.51      0.42       339\n",
            "weighted avg       0.69      0.66      0.53       339\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izppruGQTNct"
      },
      "source": [
        "# Bonus: +0.25 puntos en cualquier pregunta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YW0aeK2KTNct"
      },
      "source": [
        "**Pregunta 1**: Replicar la parte anterior utilizando embeddings pre-entrenados en un dataset m√°s grande y obtener mejores resultados. Les puede servir [√©sta](https://radimrehurek.com/gensim/downloader.html#module-gensim.downloader) documentacion de gensim **(0.25 puntos)**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvHcVS3sTNct"
      },
      "source": [
        "**Respuesta**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSc8p-T8TNcu"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwaDuQqCOyLJ"
      },
      "source": [
        "# **Tarea 4 - CC6205 Natural Language Processing üìö**\n",
        "\n",
        "**Integrantes:** Arturo Lazcano\n",
        "\n",
        "**Fecha l√≠mite de entrega üìÜ:** Martes 13 de junio.\n",
        "\n",
        "**Tiempo estimado de dedicaci√≥n:** 12 horas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4lL5hGw07yP"
      },
      "source": [
        "Bienvenid@s a la cuarta tarea del curso de Natural Language Processing (NLP).\n",
        "En esta tarea estaremos tratando el problema de **tagging** (generaci√≥n de secuencias de etiquetas del mismo largo que la secuencia de input), el uso de **Convolutional Neural Networks** y **Recurrent Neural Networks**, e implementaremos una red usando PyTorch.\n",
        "\n",
        "Usen $\\LaTeX$ para las f√≥rmulas matem√°ticas. En la parte de programaci√≥n pueden usar lo que quieran, pero la [Auxiliar 3](https://youtu.be/36WTXvg3zh0) les puede ser de *gran ayuda*.\n",
        "\n",
        "**Instrucciones:**\n",
        "- La tarea se realiza en grupos de **m√°ximo** 2 personas. Puede ser invidivual pero no es recomendable.\n",
        "- La entrega es a trav√©s de u-cursos a m√°s tardar el d√≠a estipulado arriba. No se aceptan atrasos.\n",
        "- El formato de entrega es este mismo Jupyter Notebook.\n",
        "- Al momento de la revisi√≥n tu c√≥digo ser√° ejecutado. Por favor verifica que tu entrega no tenga errores de compilaci√≥n.\n",
        "- En el horario de auxiliar pueden realizar consultas acerca de la tarea a trav√©s del canal de Discord del curso.\n",
        "\n",
        "Si a√∫n no han visto las clases, se recomienda visitar los links de las referencias.\n",
        "\n",
        "**Referencias:**\n",
        "\n",
        "- [Tagging, and Hidden Markov Models ](http://www.cs.columbia.edu/~mcollins/cs4705-spring2019/slides/tagging.pdf) (slides by Michael Collins), [notes](http://www.cs.columbia.edu/~mcollins/hmms-spring2013.pdf), [video 1](https://youtu.be/-ngfOZz8yK0), [video 2](https://youtu.be/Tjgb-yQOg54), [video 3](https://youtu.be/aaa5Qoi8Vco), [video 4](https://youtu.be/4pKWIDkF_6Y)\n",
        "- [MEMMs and CRFs](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-CRF.pdf): [notes 1](http://www.cs.columbia.edu/~mcollins/crf.pdf), [notes 2](http://www.cs.columbia.edu/~mcollins/fb.pdf), [video 1](https://youtu.be/qlI-4lSUDkg), [video 2](https://youtu.be/PLoLKQwkONw), [video 3](https://youtu.be/ZpUwDy6o28Y)\n",
        "- [Convolutional Neural Networks](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-CNN.pdf): [video](https://youtu.be/lLZW5Fn40r8)\n",
        "- [Recurrent Neural Networks](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-RNN.pdf): [video 1](https://youtu.be/BmhjUkzz3nk), [video 2](https://youtu.be/z43YFR1iIvk), [video 3](https://youtu.be/7L5JxQdwNJk)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hidden Markov Models (HMM), Maximum Entropy Markov Models (MEMM) and Conditional Random Field(CRF) (1,5 puntos)"
      ],
      "metadata": {
        "id": "ANqzQ3G9WNw3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWXD3D7RYKJ-"
      },
      "source": [
        "### Pregunta 1 (1 pt)\n",
        "Para un problema de POS tagging se define el conjunto de etiquetas $S = \\{ \\text{DET}, \\text{NOUN}, \\text{VERB}, \\text{ADP} \\}$ y se tiene un Hidden Markov Model con los siguientes par√°metros estimados a partir de un corpus de entrenamiento:\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{split}\n",
        "q(\\text{NOUN}| \\text{ VERB}, \\text{DET}) &= 0.3 \\\\\n",
        "q(\\text{NOUN}|\\ w, \\text{DET}) &= 0 \\qquad \\forall w \\in S, w \\neq \\text{VERB} \\\\\n",
        "q(\\text{DET}| \\text{ VERB}, \\text{NOUN}) &= 0.4 \\\\\n",
        "q(\\text{DET}|\\ w, \\text{NOUN}) &= 0 \\qquad \\forall w \\in S, w \\neq \\text{VERB} \\\\\n",
        "e(the|\\text{ DET}) &= 0.5 \\\\\n",
        "e(pasta|\\text{ NOUN}) &= 0.6\n",
        "\\end{split}\n",
        "\\end{equation}\n",
        "\n",
        "Luego para la oraci√≥n: `the man is pouring sauce on the pasta`, se tiene una tabla de programaci√≥n din√°mica con los siguientes valores:\n",
        "\\begin{equation}\n",
        "\\begin{split}\n",
        "\\pi(7,\\text{DET},\\text{DET})&=0.1\\\\\n",
        "\\pi(7,\\text{NOUN},\\text{DET})&=0.2\\\\\n",
        "\\pi(7,\\text{VERB},\\text{DET})&=0.01\\\\\n",
        "\\pi(7,\\text{ADP},\\text{DET})&=0.5\n",
        "\\end{split}\n",
        "\\end{equation}\n",
        "\n",
        "Con esta informaci√≥n, calcule el valor de $\\pi(8,\\text{DET},\\text{NOUN})$. Puede dejar el resultado expresado como una fracci√≥n.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EzgysW9kGi-"
      },
      "source": [
        "**Respuesta**\n",
        "\n",
        "Recordando que, gracias al algoritmo de Viterbi, la programaci√≥n din√°mica hace posible calcular estos valores teniendo informaci√≥n solamente de algunos casos anteriores.\n",
        "As√≠,\n",
        "\n",
        "$\\pi(8,\\text{DET},\\text{NOUN}) = $ M√°xima probabilidad de que se termine con DET, NOUN (D, N respectivamente) en la posici√≥n 8. Luego,\n",
        "\n",
        "$\\pi(8,\\text{DET},\\text{NOUN}) = \\max_{w \\in S_6} [\\pi(7,w,\\text{D}) \\times q(\\text{N}|w,\\text{D}) \\times e(\\text{pasta}|\\text{N})]$\n",
        "\n",
        "Con esto, debemos probar los valores dados por la tabla din√°mica para poder obtener el m√°ximo, esto iteranco con $w \\in S$. Notando que $q(\\text{N}|w,\\text{D}) = 0$ para cada $w \\neq \\text{VERB}$, es f√°cil ver que se anula cada opci√≥n, por lo que la √∫nica que no es 0 es usando $w = \\text{VERB}$ resultando:\n",
        "\n",
        "$\\pi(8,\\text{DET},\\text{NOUN}) = \\pi(7,\\text{V},\\text{D}) \\times q(\\text{N}|\\text{V},\\text{D}) \\times e(\\text{pasta}|\\text{N}) = 0.01 \\cdot 0.3 \\cdot 0.6 = 0.0018$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiwJb_vmkKLZ"
      },
      "source": [
        "### Pregunta 2 (0.5 pts)\n",
        "Comente  sobre las similitudes o diferencias entre los HMMs, MEMMs y CRFs. Para esto, responda las siguientes preguntas.\n",
        "\n",
        "#### 2.1. ¬øPara qu√© tipo de tarea sirven? D√© dos ejemplo de este tipo de tarea y descr√≠balos brevemente. (0.1 pts)\n",
        "\n",
        "**Respuesta:**\n",
        "\n",
        "Los HMMs, MEMMs y CRFs son √∫tiles para tareas de etiquetado secuencial. Para ello hay 2 tareas usuales que son POS tagging (Part-Of-Speech) y NER (Named Entity Recognition). Esta primera tarea busca asignar una etiqueta gramatical a cada palabra en una oraci√≥n, como sustantivo, verbo, adjetivo, etc. Por otro lado, esta segunda tarea, su objetivo es identificar y clasificar menciones de entidades nombradas en un texto, como nombres de personas, organizaciones, ubicaciones, etc.\n",
        "\n",
        "#### 2.2. ¬øQu√© modelos usan features? ¬øQu√© ventajas conlleva esto? (0.1 pts)\n",
        "\n",
        "**Respuesta:**\n",
        "\n",
        "Los modelos MEMMs y CRFs usan features. Posibles ventajas de esto es el mejor manejo de dependencias contextuales, poseen mejor y m√°s rica representaci√≥n y el hecho de poder elegir un vector de caracter√≠sticas entrega una mayor flexibilidad a la hora de querer ajustar lo mejor posible un modelo.\n",
        "\n",
        "#### 2.3. ¬øC√≥mo maneja cada uno de los modelos las palabras con baja frecuencia en el set de train? (0.1 pts)\n",
        "\n",
        "**Respuesta:**\n",
        "\n",
        "\n",
        "\n",
        "*   HMM's: Separa palabras dado un umbral de frecuencia. Luego, para estas palabras de baja aparici√≥n en el texto, las mapea a un conjunto finito (peque√±o) dependiendo del tipo de palabra. Por ejemplo, \"90\" ser√≠a mapeado a una clase tipo \"TwoDigitsNumber\"\n",
        "*   MEMM's y CRF's: Extracci√≥n de caracter√≠sticas adicionales (por ejemplo, morfol√≥gica, l√©xica, sint√°ctica, entre otras), aprovechamiento de la informaci√≥n contextual e incluso t√©cnicas de suavizado.\n",
        "\n",
        "\n",
        "\n",
        "#### 2.4. ¬øQu√© le permite a los CRF realizar decisiones globales? ¬øQu√© diferencia con respecto a los MEMMs permite lograr esto? ¬øPor qu√© los HMMs tampoco son capaces de tomar decisiones globales? (0.1 pts)\n",
        "\n",
        "**Respuesta:**\n",
        "\n",
        "Esto se debe a que la normalizaci√≥n es global, pues involucra a la suma de todas las posibles secuencias de tag $S^m$, mientras que a los modelos MEMMs, debido a que realizan una normalizaci√≥n local, se pierde informaci√≥n pudiendo incluso clasificar incorrectamente el tipo de una palabra.\n",
        "Por otro lado, los modelos HMM son locales, esto debido a su definici√≥n, ya que aprovechan t√©cnicas de cadenas de Markov, las cuales poseen p√©rdida de memoria, haciendo estos modelos locales en cierta vecindad de alguna palabra objetivo.\n",
        "\n",
        "#### 2.5 Dado una secuencia de $x_1, ..., x_m$ ¬øCu√°ntas posibles secuencias de etiquetas se pueden generar para un conjunto de etiquetas $S$ con $|S|=k$ ? ¬øAnalizarlas todas ser√≠a computacionalmente tratable? (0.1 pts)\n",
        "\n",
        "**Respuesta:**\n",
        "\n",
        "Si el conjunto de etiquetas posee cardinal $k$, cada palabra tiene $k$ posibles etiquetas, por lo que en una secuencia de $m$ palabras, el conjunto de todas las posibles secuancias tiene cardinal $k^m$.\n",
        "Viendo esto en un ejemplo sencillo, para una secuencia de 10 palabras y un conjunto de etiquetas con cardinal 5, el conjunto de todas las posibles etiquetas tiene cardinal $5^{10} = 9.765.625$, lo cual lo convierte en algo computacionalmente dif√≠cil de tratar, ya que esto tiene un crecimiento exponencial en el largo de la secuencia. Esto afecta directamente pues en los problemas pr√°cticos, se tienen corpus de un largo mucho mayor a 10 como en el ejemplo anterior."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Networks (0,5 puntos)"
      ],
      "metadata": {
        "id": "44ACHHZIWGF1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClRAHR95Y8aB"
      },
      "source": [
        "### Pregunta 3 (0,5 puntos)\n",
        "\n",
        "Considere la frase $w_{1..7}=$ `El agua moja y el fuego quema` $=[El, agua, moja, y, el, fuego, quema]$.\n",
        "\n",
        "La siguiente matriz de embeddings, donde la i-√©sima fila corresponde al vector de embedding de la i-√©sima palabra, ordenadas seg√∫n aparecen en la frase. (vectores de largo 2).\n",
        "\\begin{equation}\n",
        "E = \\begin{pmatrix}\n",
        "2 & 2\\\\\n",
        "0 & -2\\\\\n",
        "0 & 1\\\\\n",
        "-2 & 1\\\\\n",
        "1 & 0\\\\\n",
        "-1 & 1\\\\\n",
        "1 & 1\n",
        "\\end{pmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "Los siguientes 3 filtros\n",
        "\\begin{equation}\n",
        "U = \\begin{pmatrix}\n",
        "-1 & 1 & 0\\\\\n",
        "1 & 1 & 0\\\\\n",
        "0 & 0 & -1\\\\\n",
        "1 & -1 & -1\\\\\n",
        "-1 & -1 & 1\\\\\n",
        "1 & 0 & -1\n",
        "\\end{pmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "Y la funci√≥n de activaci√≥n\n",
        "\\begin{equation}\n",
        "tanh = \\frac{e^{2x} - 1}{e^{2x} + 1}\n",
        "\\end{equation}\n",
        "\n",
        "Usando estos param√°tros escriba los pasos para calcular la representaci√≥n (vector) resultante de aplicar la operaci√≥n de convoluci√≥n (sin padding) + max pooling. ¬øDe qu√© tama√±o ser√≠a la ventana que debemos usar?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlQ30Arkq0u4"
      },
      "source": [
        "**Respuesta**\n",
        "\n",
        "Dados estos par√°metros, se usa a operaci√≥n $\\oplus w_{i:i+k-1}$ como la concatenaci√≥n de los vectores $w_i, ..., w_i+k-1$ donde $i$ representa siempre la fila y pertenece al conjunto $ \\{1,...,7\\}$ en el ejempo de arriba.\n",
        "En este caso, como la matriz $E$ tiene ancho 2, entonces $k=2$. Luego, se genera el vector de concatenaciones $x_i = \\oplus w_{i:i+k-1}$. As√≠, con los filtros $u$ escritos en la matriz $U$, se procede a definir $p_i = g(x_i \\cdot U + b)$ donde $b$ es un vector de bias. A este producto punto se le agrega el uso de una funci√≥n de activaci√≥n g a cada $p_i$, en este caso la tangente hiperb√≥lica.\n",
        "\n",
        "Hasta este punto, obtenemos $n-k+1 = 7-2+1 = 6$ vectores $p_{1:6}$. Luego de este proceso, se pasa a la etapa de pooling, la cual consiste en combinar los vectores $p_{1:m}$ en un solo vector $c$, donde al aplicar max pooling, lo que hacemos es definir $c_{[j]} = \\max_{1<i\\leq m} p_{i[j]}$ donde este vector final es el que captura la informaci√≥n importante de la secuencia original."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recurrent Neural Networks (1 punto)\n"
      ],
      "metadata": {
        "id": "A0rCwen3WREC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0et78Z4oKIq"
      },
      "source": [
        "### Pregunta 4 (0,5 puntos)\n",
        "Usando los embeddings de dos dimensiones de la pregunta anteror, la oraci√≥n `el fuego quema` la podemos representar por una secuencia de vectores $(\\vec{x}_1,\\vec{x}_2,\\vec{x}_3)$, con $\\vec{x}_i \\in \\mathbb{R}^{d_x}$ y $d_x=2$.\n",
        "\n",
        "Tenemos una red recurrente *Elman* definidad como:\n",
        "\\begin{equation}\n",
        "\\begin{split}\n",
        "\\vec{s}_i &= R_{SRNN}\\left (\\vec{x}_i, \\vec{s}_{i-1}\\right ) = g \\left (\\vec{s}_{i-1}W^s + \\vec{x}_i W^x + \\vec{b}\\right ) \\\\\n",
        "\\vec{y}_i &= O_{SRNN}\\left(\\vec{s}_i\\right) = \\vec{s}_i \\\\\n",
        "\\end{split}\n",
        "\\end{equation}\n",
        "donde\n",
        "\\begin{equation}\n",
        "\\vec{s}_i, \\vec{y}_i \\in \\mathbb{R}^{d_s}, \\quad W^x \\in \\mathbb{R}^{d_x \\times d_s}, \\quad W^s \\in \\mathbb{R}^{d_s \\times d_s}, \\quad \\vec{b} \\in \\mathbb{R}^{d_s},\n",
        "\\end{equation}\n",
        "y los vectores de estado $s_i$ son de tres dimensiones, $ds= 3$.\n",
        "\n",
        "Sea\n",
        "\\begin{equation}\n",
        "\\begin{split}\n",
        "\\vec{s}_0 &= [0,0,0]\\\\\n",
        "W^x &= \\begin{pmatrix}\n",
        "0 &  0 & 1\\\\\n",
        "1 & -1 & 0\n",
        "\\end{pmatrix} \\\\\n",
        "W^s &= \\begin{pmatrix}\n",
        "1 & 0 &  1\\\\\n",
        "0 & 1 & -1\\\\\n",
        "1 & 1 &  1\n",
        "\\end{pmatrix} \\\\\n",
        "\\vec{b} &= [0, 0, 0] \\\\\n",
        "g(x) &= ReLu(x) = max(0, x)\n",
        "\\end{split}\n",
        "\\end{equation}\n",
        "\n",
        "<br>\n",
        "\n",
        "Calcule manualmente los valores de los vectores $\\vec{s}_1, \\vec{s}_2,\\vec{s}_3$ y de $\\vec{y}_1, \\vec{y}_2,\\vec{y}_3$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fim2W8JioPhL"
      },
      "source": [
        "**Respuesta**\n",
        "\n",
        "$  \\vec{s}_1 = \\max(0, \\vec{s}_0W^s + \\vec{x}_1W^x + \\vec{b})   $\n",
        "\n",
        "$  \\vec{s}_2 = \\max(0, \\vec{s}_1W^s + \\vec{x}_2W^x + \\vec{b})   $\n",
        "\n",
        "$  \\vec{s}_3 = \\max(0, \\vec{s}_2W^s + \\vec{x}_3W^x + \\vec{b})   $\n",
        "\n",
        "Donde, dada la matriz de embeddings de la pregunta anterior, $\\vec{x}_1 = (1,0)$, $\\vec{x}_2 = (-1,1)$ y $\\vec{x}_3 = (1,1)$. As√≠, podemos proceder a calcular directamente los vectores $\\vec{s}_i$:\n",
        "\n",
        "$\\vec{s}_1 = \\max(0, \\vec{s}_0W^s + \\vec{x}_1W^x + \\vec{b}) = \\max\\bigg(0,\n",
        "\\begin{pmatrix}\n",
        "1 &  0\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "0 &  0 & 1\\\\\n",
        "1 & -1 & 0\n",
        "\\end{pmatrix}\\bigg)\n",
        "= \\max(0, \\begin{pmatrix}\n",
        "0 &  0 & 1\n",
        "\\end{pmatrix}) = \\begin{pmatrix}\n",
        "0 & 0 & 1\n",
        "\\end{pmatrix}$\n",
        "\n",
        "$\\vec{s}_2 = \\max(0, \\vec{s}_0W^s + \\vec{x}_1W^x + \\vec{b}) = \\max\\bigg(0,\n",
        "\\begin{pmatrix}\n",
        "0 & 0 & 1\n",
        "\\end{pmatrix}+\n",
        "\\begin{pmatrix}\n",
        "-1 & 1\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "0 &  0 & 1\\\\\n",
        "1 & -1 & 0\n",
        "\\end{pmatrix}\\bigg)\n",
        "= \\max(0, \\begin{pmatrix}\n",
        "1 & -1 & 0\n",
        "\\end{pmatrix}) = \\begin{pmatrix}\n",
        "1 & 0 & 0\n",
        "\\end{pmatrix}$\n",
        "\n",
        "$\\vec{s}_3 = \\max(0, \\vec{s}_0W^s + \\vec{x}_1W^x + \\vec{b}) = \\max\\bigg(0,\n",
        "\\begin{pmatrix}\n",
        "1 & 0 & 0\n",
        "\\end{pmatrix}+\n",
        "\\begin{pmatrix}\n",
        "1 & 1\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix}\n",
        "0 &  0 & 1\\\\\n",
        "1 & -1 & 0\n",
        "\\end{pmatrix}\\bigg)\n",
        "= \\max(0, \\begin{pmatrix}\n",
        "2 & -1 & 1\n",
        "\\end{pmatrix}) = \\begin{pmatrix}\n",
        "2 & 0 & 1\n",
        "\\end{pmatrix}$\n",
        "\n",
        "Por √∫ltimo, por definici√≥n, $\\vec{y}_i = \\vec{s}_i$, concluyendo lo pedido.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4rAT6ELxRZW"
      },
      "source": [
        "### Pregunta 5 (0.5 puntos)\n",
        "¬øDe qu√© forma las RNN y las CNN logran aprender representaciones espec√≠ficas\n",
        "para la tarea objetivo? Compare la forma en que las RNN y las CNN aprenden con los modelos que usan *features* dise√±adas manualmente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6AXbQSgA_t8"
      },
      "source": [
        "**Respuesta**\n",
        "\n",
        "*   RNN: Estas son capaces de capturar y modelar dependencias a largo plazo en secuencias. Esto se logra mediante la incorporaci√≥n de conexiones recurrentes, que permiten que la informaci√≥n fluya hacia adelante y hacia atr√°s en la red a trav√©s del tiempo. Para esto, la red hace m√∫ltiples c√°lculos de valores que dependen de su capa anterior junto con embedding de la i-√©sima palabra tal como se puede ver en la pregunta anterior (en el caso RNN Elman).\n",
        "\n",
        "*   CNN: Estas utilizan filtros convolucionales para escanear localmente las caracter√≠sticas en los datos de entrada. Estos filtros convolucionales se aplican de manera repetida a diferentes regiones del espacio de entrada, generando mapas de caracter√≠sticas que resaltan patrones y caracter√≠sticas espec√≠ficas, adem√°s existen t√©cnicas como pooling que resultan en la obtenci√≥n de las features m√°s importantes en un texto.\n",
        "Son especialmente √∫tiles para tareas de visi√≥n por computadora que involucran datos estructurados en forma de im√°genes o mapas de caracter√≠sticas.\n",
        "\n",
        "As√≠, ambos modelos aprenden features de manera autom√°tica, en contraparte con, por ejemplo, los modelos MEMM's y CRF's que tienen features dise√±adas manualmente ($\\phi$).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pregunta 6: Redes Neuronales con Pytorch (3 puntos) üí¨\n",
        "\n",
        "<center>\n",
        "<img src=\"https://www.anda.cl/wp-content/uploads/2021/03/0_5vNAtimPjYQr4W72.gif\" alt=\"chatbot\" width=\"400\">\n",
        "</center>"
      ],
      "metadata": {
        "id": "FRJkBpjWyHnb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En esta secci√≥n de la tarea deber√°n implementar un Chatbot que sea capaz de generar una conversaci√≥n *‚Äúb√°sica‚Äù* utilizando un dataset de *Star Wars*. **El objetivo** de esta pregunta es que puedan aplicar lo aprendido sobre redes neuronales utilizando Pytorch en un ejemplo pr√°ctico.  Durante el desarrollo, se espera que puedan dise√±ar un bot (que tendr√° por atr√°s un clasificador) que sea capaz de clasificar diferentes etiquetas, cosa que una vez identificada la etiqueta entregue una respuesta acorde a lo preguntado.\n",
        "\n",
        "**Aviso:** Antes de comenzar con una descripci√≥n mas profunda de esta secci√≥n, les recomendamos que visualicen y se familiaricen con el dataset entregado, de esta forma comprender√°n mejor la descripci√≥n del enunciado (aqu√≠ una peque√±a ayudita üÜò)."
      ],
      "metadata": {
        "id": "GEla92bUymrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "example_data = pd.read_json('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/star_wars_chatbot.json')\n",
        "print(\"Cantidad de tags: \", example_data['intents'].shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eKOGlMs3Dx-",
        "outputId": "08f0d563-9094-41c6-da72-a2a7c989966e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de tags:  16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuaci√≥n, ejemplos del contenido del primer registro:"
      ],
      "metadata": {
        "id": "V-6fCE5fHkNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_data['intents'][0]['patterns']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axsi27BpHGOx",
        "outputId": "a87cfe15-8305-436f-85be-7b61cfbd6435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi',\n",
              " 'Hey',\n",
              " 'How are you',\n",
              " 'Is anyone there?',\n",
              " 'Hello',\n",
              " 'Good day',\n",
              " \"What's up\",\n",
              " 'Yo!',\n",
              " 'Howdy',\n",
              " 'Nice to meet you.']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_data['intents'][0]['responses']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OV0vGdwoHeg3",
        "outputId": "19f89c53-9af4-4c47-f9e9-7a70c24570f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hey',\n",
              " 'Hello, thanks for visiting.',\n",
              " 'Hi there, what can I do for you?',\n",
              " 'Hi there, how can I help?',\n",
              " 'Hello, there.',\n",
              " 'Hello Dear',\n",
              " 'Ooooo Hello, looking for someone or something?',\n",
              " 'Yes, I am here.',\n",
              " 'Listening carefully.',\n",
              " 'Ok, I am with you.']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_data['intents'][0]['tag']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0BnYez1oGtx3",
        "outputId": "0574cb5d-fa21-4f50-f1cb-e06baff14e10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'greeting'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(example_data)):\n",
        "  print(example_data['intents'][i]['tag'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oONypinAWmW8",
        "outputId": "86005d86-e1eb-407f-eb08-f5ae0143a403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "greeting\n",
            "goodbye\n",
            "thanks\n",
            "tasks\n",
            "alive\n",
            "Menu\n",
            "help\n",
            "mission\n",
            "jedi\n",
            "sith\n",
            "bounti hounter\n",
            "funny\n",
            "about me\n",
            "creator\n",
            "myself\n",
            "stories\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "1O0nbqJFW2tI",
        "outputId": "f537e0b1-2a99-49ad-ec68-6dc0d626e479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              intents\n",
              "0   {'tag': 'greeting', 'patterns': ['Hi', 'Hey', ...\n",
              "1   {'tag': 'goodbye', 'patterns': ['Bye', 'See yo...\n",
              "2   {'tag': 'thanks', 'patterns': ['Thanks', 'Than...\n",
              "3   {'tag': 'tasks', 'patterns': ['What can you do...\n",
              "4   {'tag': 'alive', 'patterns': ['Are you alive.'...\n",
              "5   {'tag': 'Menu', 'patterns': ['Which items do y...\n",
              "6   {'tag': 'help', 'patterns': ['I am looking for...\n",
              "7   {'tag': 'mission', 'patterns': ['I am on missi...\n",
              "8   {'tag': 'jedi', 'patterns': ['Tell me top 10 j...\n",
              "9   {'tag': 'sith', 'patterns': ['Tell me top 10 s...\n",
              "10  {'tag': 'bounti hounter', 'patterns': ['Tell m...\n",
              "11  {'tag': 'funny', 'patterns': ['Tell me a joke!...\n",
              "12  {'tag': 'about me', 'patterns': ['Do you know ...\n",
              "13  {'tag': 'creator', 'patterns': ['Who is your c...\n",
              "14  {'tag': 'myself', 'patterns': ['Tell me about ...\n",
              "15  {'tag': 'stories', 'patterns': ['Tell me a sto..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf1d9015-a87b-475c-9262-8e6612dbbf91\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>intents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'tag': 'greeting', 'patterns': ['Hi', 'Hey', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'tag': 'goodbye', 'patterns': ['Bye', 'See yo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'tag': 'thanks', 'patterns': ['Thanks', 'Than...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'tag': 'tasks', 'patterns': ['What can you do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'tag': 'alive', 'patterns': ['Are you alive.'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>{'tag': 'Menu', 'patterns': ['Which items do y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>{'tag': 'help', 'patterns': ['I am looking for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>{'tag': 'mission', 'patterns': ['I am on missi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>{'tag': 'jedi', 'patterns': ['Tell me top 10 j...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>{'tag': 'sith', 'patterns': ['Tell me top 10 s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>{'tag': 'bounti hounter', 'patterns': ['Tell m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>{'tag': 'funny', 'patterns': ['Tell me a joke!...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>{'tag': 'about me', 'patterns': ['Do you know ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>{'tag': 'creator', 'patterns': ['Who is your c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>{'tag': 'myself', 'patterns': ['Tell me about ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>{'tag': 'stories', 'patterns': ['Tell me a sto...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf1d9015-a87b-475c-9262-8e6612dbbf91')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cf1d9015-a87b-475c-9262-8e6612dbbf91 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cf1d9015-a87b-475c-9262-8e6612dbbf91');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Del dataset cargado podemos notar que este viene en un formato `JSON`, por lo que sus datos est√°n almacenados en diccionarios. Las llaves de los diccionarios no son aleatorias y estos nos sirven para identificar puntos relevantes en el desarrollo del bot. A continuaci√≥n, se realiza una peque√±a descripci√≥n de las llaves:\n",
        "\n",
        "- `patterns`: Almacena los patrones con los que entrenaremos el modelo üòÆ, en otras palabras, es el corpus de entrenamiento que contiene solo preguntas o expresiones que deber√° responder el bot.\n",
        "- `responses`: Son las respuestas üôã relacionadas a los `patterns`, estas las utilizaremos en una etapa posterior a la clasificaci√≥n, para dar una respuesta aleator√≠a al usuario.\n",
        "- `tag`: Son las labels con las que entrenaremos nuestro modelo üíª.\n",
        "\n",
        "En s√≠ntesis, las `keys` relevantes para el entrenamiento de nuestra red neuronal ser√°n `patterns` (corpus) y `tag` (etiquetas)."
      ],
      "metadata": {
        "id": "v6BvAWCw3zPM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Explicaci√≥n de la tarea a realizar:"
      ],
      "metadata": {
        "id": "KlOAdMjSSzNN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explicaci√≥n de la tarea a realizar**: Implemente una Class llamada `CNNClassifier` que sea capaz de entrenar un modelo de texto a trav√©s de una red neuronal Feed Forward y una arquitectura convolucional (CNN 1D) [`torch.nn.Conv1d`](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#conv1d) . Para el dise√±o de las redes tienen completa libertad, pero se le aconseja que se gu√≠en de la √∫ltima auxiliar para la construcci√≥n. Es **important√≠simo** que el modelo a crear posea una capa de `Embedding` que se genere en base al entrenamiento del modelo. Creado el modelo, construya una funci√≥n batch para cargar los datos de entrenamiento del modelo.\n",
        "\n",
        "Construido el modelo, compare los resultados obtenidos para una red feed forward y una cnn. Para la comprobaci√≥n de sus resultados ejecute el chatbot y pruebelo, ¬øqu√© configuraci√≥n tiene mejores resultados?, ¬øa qu√© se deberan estos resultados?\n",
        "\n",
        "Ojo que un ejemplo de prueba con el chatbot puede ser (agregue mas preguntas ud):\n",
        "\n",
        "```\n",
        "Let's chat! (type 'finish_chat' to finish the chat)\n",
        "You: hi\n",
        "GA-97: Yes, I am here.\n",
        "You: can you tell me a joke?\n",
        "GA-97: Have you tried the gluten-free Wookiee treats? No, but I heard they are a little Chewy.\n",
        "```\n",
        "\n",
        "El resto del c√≥digo referido a la ejecuci√≥n del chat se los entregamos, por lo que no deber√≠an tener mayores problemas üò∏ (en caso de tener problemas con su c√≥digo, puede modificar cualquier parte sugerida siempre y cuando cumpla lo solicitado).\n",
        "\n",
        "**Igual [mucho texto](https://i0.wp.com/elgeneracionalpost.com/wp-content/uploads/2020/07/mucho-texto.jpg?fit=1280%2C720&ssl=1).... En resumen, ¬øQu√© se solicita?:**\n",
        "\n",
        "- [ ] Dise√±ar una red neuronal Feed Forward.\n",
        "- [ ] Dise√±ar un red convolucional.\n",
        "- [ ] Utilizar una capa de embeddings para generar representaciones vectoriales del corpus.\n",
        "- [ ] Crear el m√©todo forward de la clase `CNNClassifier`.\n",
        "- [ ] Crear la funci√≥n BATCH.\n",
        "- [ ] Probar el modelo y comparar los resultados obtenidos con la red Feed Forward y la red CNN. Comente sus resultados de forma cualitativa, se√±alando con qu√© tipo de red obtuvo mejores resultados con el chatbot.\n",
        "\n",
        "**Nota-1:** El modelo creado debe tener la opci√≥n de entrenar a traves de una feed forward y una CNN. Esto no significa que entrenar√° una FF y una CN, el modelo deber√° recibir un booleano que especifique que tipo de red utilizar√°.\n",
        "\n",
        "**Nota-2:** El dataset se descargar√° autom√°ticamente en la secci√≥n `Carga de Dataset üìö`, no os preocup√©is."
      ],
      "metadata": {
        "id": "9yGApnWVI4cO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pasemos al C√≥digo ü¶æ\n",
        "\n",
        "Esqueleto propuesto (se **RECOMIENDA** que cambien **SOLO** la red neuronal y la funci√≥n Batch) ü¶¥:"
      ],
      "metadata": {
        "id": "a4bKfAdEy3oD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Instalamos librerias necesarias e importamos üòÄ"
      ],
      "metadata": {
        "id": "RUwxivx2MpMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Esto toma su tiempo en ejecutarse\n",
        "%%capture\n",
        "!pip install torch==1.8.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install torchtext==0.9.0"
      ],
      "metadata": {
        "id": "TjSZkBsk1H4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import torch\n",
        "import random\n",
        "from random import choice\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torch.optim import SGD, lr_scheduler\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from itertools import zip_longest\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer"
      ],
      "metadata": {
        "id": "RfZ6SL-Q1Kwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Carga de Dataset üìö"
      ],
      "metadata": {
        "id": "oj-Epe7XJLrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we obtain the dataset\n",
        "!wget 'https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/star_wars_chatbot.json'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvlLqYRrVN6l",
        "outputId": "70d7bf27-851f-4e38-bc8a-88ac8d395ff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-15 20:43:14--  https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/star_wars_chatbot.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14469 (14K) [text/plain]\n",
            "Saving to: ‚Äòstar_wars_chatbot.json‚Äô\n",
            "\n",
            "\rstar_wars_chatbot.j   0%[                    ]       0  --.-KB/s               \rstar_wars_chatbot.j 100%[===================>]  14.13K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2023-06-15 20:43:14 (14.4 MB/s) - ‚Äòstar_wars_chatbot.json‚Äô saved [14469/14469]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset using json\n",
        "with open('star_wars_chatbot.json', 'r') as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "# Create a vocab with the dataset and get the number of classes that have\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "vocab = build_vocab_from_iterator(tokenizer(x) for list_words in dataset['intents'] for x in list_words['patterns'])\n",
        "num_classes = len(dataset['intents'])\n",
        "\n",
        "# Define a list with the labels\n",
        "labels = sorted(set([tag for tag in [intents['tag'] for intents in dataset['intents']]]))\n",
        "# Define a train_list where we can find the info in the format: [(tag_0, text_0)...,(tag_n-1, text_n-1)]\n",
        "train_list = [(labels.index(intents['tag']), text) for intents in dataset['intents'] for text in intents['patterns']]\n",
        "\n",
        "#vocab.set_default_index(0)\n",
        "vocab.insert_token('<pad>', 1)\n",
        "#stoi = vocab.get_stoi()"
      ],
      "metadata": {
        "id": "MbbIsFUG1TXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3d-LTfkdd6n",
        "outputId": "70d18ba7-ee6f-48bf-ccde-c41d925d4d82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Menu',\n",
              " 'about me',\n",
              " 'alive',\n",
              " 'bounti hounter',\n",
              " 'creator',\n",
              " 'funny',\n",
              " 'goodbye',\n",
              " 'greeting',\n",
              " 'help',\n",
              " 'jedi',\n",
              " 'mission',\n",
              " 'myself',\n",
              " 'sith',\n",
              " 'stories',\n",
              " 'tasks',\n",
              " 'thanks']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Creaci√≥n del modelo (2 puntos en total)"
      ],
      "metadata": {
        "id": "a52SUNKPJQxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Construya el modelo\n",
        "class CNNClassifier(nn.Module):\n",
        "    \"\"\"Clasificador con red neuronal convolucional.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, embed_dim=32, num_classes=10,\n",
        "                 use_cnn=False, cnn_pool_channels=24, cnn_kernel_size=3):\n",
        "      \"\"\"Inicializar clase CNNClassifier.\n",
        "\n",
        "      Parameters\n",
        "      ----------\n",
        "      vocab_size : int\n",
        "          Tama√±o del vocabulario.\n",
        "\n",
        "      embed_dim : int\n",
        "          dimensi√≥n de la capa de embeddings (vocab_size * embed_dim).\n",
        "\n",
        "      num_classes : int\n",
        "          N√∫mero de clases del output de la capa lineal.\n",
        "\n",
        "      use_cnn : bool\n",
        "          True indica que se debe usar cnn. False que no debe ser usada.\n",
        "\n",
        "      cnn_pool_channels : int\n",
        "          N√∫mero de canales de salida de la convoluci√≥n.\n",
        "\n",
        "      cnn_kernel_size : int\n",
        "          Tama√±o del kernel de la convoluci√≥n.\n",
        "\n",
        "      \"\"\"\n",
        "      super().__init__()\n",
        "\n",
        "\n",
        "      #if self.use_cnn==True:\n",
        "        # Usar red feed forward\n",
        "      #else:\n",
        "\n",
        "      self.use_cnn = use_cnn\n",
        "\n",
        "      # Creamos la capa de embedding\n",
        "      self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "\n",
        "      # Creamos la capa de convoluci√≥n\n",
        "      self.conv = nn.Conv1d(\n",
        "            in_channels=1,\n",
        "            out_channels=cnn_pool_channels,\n",
        "            kernel_size=cnn_kernel_size * embed_dim,\n",
        "            stride=embed_dim,\n",
        "            padding=cnn_kernel_size * embed_dim\n",
        "        )\n",
        "\n",
        "      # Calculamos el tama√±o de entrada de la capa lineal\n",
        "      fc_in_size = cnn_pool_channels\n",
        "\n",
        "      # Creamos la capa lineal\n",
        "      self.fc = nn.Linear(fc_in_size, num_classes)\n",
        "\n",
        "      # Inicializamos los pesos de las capas\n",
        "      self.init_weights()\n",
        "\n",
        "\n",
        "    def init_weights(self):\n",
        "      \"\"\"Inicia los pesos de la red.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        self :\n",
        "            Red neuronal convolucional.\n",
        "        \"\"\"\n",
        "\n",
        "      # Definimos el rango de los valores iniciales de los pesos\n",
        "      initrange = 0.5\n",
        "\n",
        "      # Inicializamos los pesos de la capa de embedding\n",
        "      self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "      # Inicializamos los pesos de la capa lineal\n",
        "      self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "      # Inicializamos los sesgos de la capa lineal en cero\n",
        "      self.fc.bias.data.zero_()\n",
        "\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "      \"\"\"realiza el traspaso de informaci√≥n entre neuronas (capas).\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        text : str\n",
        "            Oraci√≥n a pasar a tensor.\n",
        "\n",
        "        offset : array\n",
        "            √çndices para transformar a tensor el texto.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        Tensor\n",
        "            Resultado final mediante funci√≥n de activaci√≥n log softmax.\n",
        "        \"\"\"\n",
        "\n",
        "      # Preparamos el input de la capa de embeddings a partir de text y offsets\n",
        "      text = torch.tensor(\n",
        "          list(\n",
        "              zip(\n",
        "                  *zip_longest(\n",
        "                      *([text[o:offsets[i+1]] for i, o in enumerate(offsets[:-1])] + [text[offsets[-1]:len(texts)]]),\n",
        "                      fillvalue=vocab[\"<pad>\"]\n",
        "                  )\n",
        "              )\n",
        "          )\n",
        "      ).to(text.device)\n",
        "\n",
        "      # Obtenemos la representaci√≥n de la frase a partir de la capa de embedding\n",
        "      h = self.embedding(text)\n",
        "\n",
        "      # Aplicamos la capa de convoluci√≥n\n",
        "      h = h.view(h.size(0), 1, -1)\n",
        "      h = torch.relu(self.conv(h))\n",
        "      h = h.mean(dim=2)\n",
        "\n",
        "      # Obtenemos el resultado final a partir de la capa lineal\n",
        "      output = self.fc(h)\n",
        "\n",
        "      # Aplicamos la funci√≥n de activaci√≥n log-softmax\n",
        "      return F.log_softmax(output, dim=1)"
      ],
      "metadata": {
        "id": "n-vQ24tMJG5H"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Funci√≥n Batch üë∑ (0,5 puntos)"
      ],
      "metadata": {
        "id": "dGN-T0JoJtmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defina su funci√≥n de BATCH\n",
        "def generate_batch(batch):\n",
        "  \"\"\"Genera un subconjunto de datos.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  batch : list of tuples\n",
        "      Objeto a tokenizar, transformando a tensor junto con sus clases.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  big_text: Tensor\n",
        "      Texto tokenizado y transformado a tensor.\n",
        "\n",
        "  offsets: Tensor\n",
        "    √çndices para transformar a tensor.\n",
        "\n",
        "  label: Tensor\n",
        "    Clase a la que pertenece la oraci√≥n.\n",
        "  \"\"\"\n",
        "  label = torch.tensor([entry[0] for entry in batch])\n",
        "  texts = [tokenizer(entry[1]) for entry in batch]\n",
        "  offsets = [0] + [len(text) for text in texts]\n",
        "  offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "  #big_text = torch.cat([torch.tensor([vocab[t] if t in stoi else 0 for t in text]) for text in texts])\n",
        "  big_text = torch.cat([torch.tensor([vocab.get_stoi()[t] for t in text]) for text in texts])\n",
        "\n",
        "  return big_text, offsets, label\n",
        "\n",
        "  #el perro labra y corre mucho-> pronombre, sujeto, verbo"
      ],
      "metadata": {
        "id": "K1AZpXc7JxTa"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Entrenamiento ü•ä"
      ],
      "metadata": {
        "id": "YChwpNrrNRBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"GPU is avaible: {device}\")\n",
        "\n",
        "# Define the different inputs in our model\n",
        "num_epochs = 1000\n",
        "BATCH_SIZE = 16\n",
        "LR = 1e-1\n",
        "INPUT_SIZE = len(vocab)\n",
        "OUTPUT_SIZE = num_classes\n",
        "USE_CNN = False\n",
        "\n",
        "# Define model, optimizer, loss and scheduler (Q: ¬øWhat is it?)\n",
        "model = CNNClassifier(INPUT_SIZE, num_classes=OUTPUT_SIZE, use_cnn=USE_CNN).to(device)\n",
        "optimizer = SGD(model.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=[lambda epoch: .9 ** (epoch // 10)])\n",
        "\n",
        "print(f'train: {len(train_list)} elements')\n",
        "\n",
        "# We train the model using the intents\n",
        "loss_list= []\n",
        "for epoch in range(1, num_epochs):\n",
        "  train_loader = DataLoader(train_list, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "  for i, (texts, offsets, cls) in enumerate(train_loader):\n",
        "    texts = texts.to(device)\n",
        "    offsets = offsets.to(device)\n",
        "    cls = cls.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(texts, offsets)\n",
        "    loss = criterion(output, cls)\n",
        "    total_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  loss_list.append(loss.item())\n",
        "  sys.stdout.write('\\rEpoch: {0:03d} \\t iter-Loss: {1:.3f}'.format(epoch+1, loss.item()))\n",
        "\n",
        "print(f'final loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5eRWRD_J0Km",
        "outputId": "fbef1617-c53b-418e-e36d-f14b8d08df12"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is avaible: cpu\n",
            "train: 97 elements\n",
            "Epoch: 1000 \t iter-Loss: 0.000final loss: 0.0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### A probar! üß™"
      ],
      "metadata": {
        "id": "9dlS4_X-L3DN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is working?, Try the next example!\n",
        "qText = \"'Do you know any joke?'\" # this must classify the label \"funny\"\n",
        "\n",
        "X = torch.tensor([vocab.get_stoi()[t] for t in tokenizer(qText)]).to(device)\n",
        "\n",
        "model.eval()\n",
        "output = model(X, torch.tensor([0], dtype=torch.long).to(device))\n",
        "_, predicted = torch.max(output, dim=1)\n",
        "labels[predicted]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "6IhhAKFXL3eH",
        "outputId": "5420b668-37cd-4c31-ddd4-efcca87673c7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'funny'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ya pero prometiste hacer un chatbot, no una simple clasificaci√≥n...."
      ],
      "metadata": {
        "id": "udemze3zL549"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Guardamos modelo ü¶∫ (opcional)"
      ],
      "metadata": {
        "id": "OpSYGx2tL0tC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We save de model using pytorch (this is optional, just to learn how to do this in pytorch)\n",
        "data = {\n",
        "\"model_state\": model.state_dict(),\n",
        "\"input_size\": INPUT_SIZE,\n",
        "\"output_size\": OUTPUT_SIZE,\n",
        "\"use_cnn\": USE_CNN,\n",
        "\"labels\": labels\n",
        "        }\n",
        "\n",
        "FILE = \"data.pth\"\n",
        "torch.save(data, FILE)\n",
        "\n",
        "print(f'training complete. file saved to {FILE}')"
      ],
      "metadata": {
        "id": "ZBC4TyiqLzDv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c813af26-33f3-4c52-fd83-a8734bcbdccf"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training complete. file saved to data.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Chatbot üí¨"
      ],
      "metadata": {
        "id": "ZYClbTtsMCjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "with open('star_wars_chatbot.json', 'r') as json_data:\n",
        "    intents = json.load(json_data)\n",
        "\n",
        "FILE = \"data.pth\"\n",
        "data = torch.load(FILE)\n",
        "\n",
        "INPUT_SIZE = data[\"input_size\"]\n",
        "OUTPUT_SIZE = data[\"output_size\"]\n",
        "USE_CNN = data[\"use_cnn\"]\n",
        "labels = data['labels']\n",
        "model_state = data[\"model_state\"]\n",
        "\n",
        "model = CNNClassifier(INPUT_SIZE, num_classes=OUTPUT_SIZE, use_cnn=USE_CNN).to(device)\n",
        "model.load_state_dict(model_state)\n",
        "model.eval()\n",
        "\n",
        "# Dictionary with the answers\n",
        "responses = {key['tag']: key['responses'] for key in dataset['intents']}\n",
        "\n",
        "bot_name = \"GA-97\"\n",
        "print(\"Let's chat! (type 'finish_chat' to finish the chat)\")\n",
        "while True:\n",
        "    q_text = input(\"You: \")\n",
        "    q_text = q_text\n",
        "    if q_text == 'finish_chat':\n",
        "        break\n",
        "\n",
        "    X = torch.tensor([vocab.get_stoi()[t] for t in tokenizer(q_text)]).to(device)\n",
        "    output = model(X, torch.tensor([0], dtype=torch.long).to(device))\n",
        "    _, predicted = torch.max(output, dim=1)\n",
        "\n",
        "    tag = labels[predicted.item()]\n",
        "\n",
        "    probs = torch.softmax(output, dim=1)\n",
        "    prob = probs[0][predicted.item()]\n",
        "    if prob.item() > 0.50:\n",
        "      print(f\"{bot_name}: {random.choice(responses[tag])}\")\n",
        "    else:\n",
        "      print(f\"{bot_name}: My model can't understand you...\")"
      ],
      "metadata": {
        "id": "c249zUwiMBxb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "outputId": "6b49110a-6df9-4f73-8609-f353ff541779"
      },
      "execution_count": 28,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Let's chat! (type 'finish_chat' to finish the chat)\n",
            "You: hey!\n",
            "GA-97: Hello, there.\n",
            "You: how are you?\n",
            "GA-97: Hey\n",
            "You: what's your name?\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-1b590a983102>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_stoi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-1b590a983102>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_stoi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'name'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Comente los resultados aqu√≠ (0,5 puntos)"
      ],
      "metadata": {
        "id": "5Hu2QTuSURCt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como se ha podido ver en esta tarea, se ha podido trabajar de buena manera el problema de tagging, junto con redes neuronales (convolucionales y recurrentes). Por otro lado, en la implementaci√≥n de este chat-bot han aparecido carencias, ya sea en la definici√≥n de las redes o en la funci√≥n de batch a usar. Sin embargo, se considera que va por buen camino dado que el bot ha sido capaz de responder cosas, sin tanto sentido pero indicando que la implementaco√≥n va por buen camino.\n",
        "\n",
        "Con respecto a los datos, se piensa que son pocos considerando que esta m√°quina debe aprender a responder un mayor conjunto de preguntas del usuario."
      ],
      "metadata": {
        "id": "fdFV63WVUX32"
      }
    }
  ]
}